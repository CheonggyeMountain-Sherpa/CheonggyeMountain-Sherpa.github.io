<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>KLUE - Relation Extraction</title>
    <link href="/KLUE_RE/"/>
    <url>/KLUE_RE/</url>
    
    <content type="html"><![CDATA[<h1 id="ì²­ê³„ì‚°ì…°ë¥´íŒŒì˜-KLUE-RE-ë“±ë°˜ì¼ì§€"><a href="#ì²­ê³„ì‚°ì…°ë¥´íŒŒì˜-KLUE-RE-ë“±ë°˜ì¼ì§€" class="headerlink" title="ì²­ê³„ì‚°ì…°ë¥´íŒŒì˜ KLUE-RE ë“±ë°˜ì¼ì§€"></a>ì²­ê³„ì‚°ì…°ë¥´íŒŒì˜ KLUE-RE ë“±ë°˜ì¼ì§€</h1><p>ì•½ 12ì¼ë™ì•ˆ ì°¸ì—¬í–ˆë˜ P Stageì˜ <code>KLUE - Relation Extraction</code> ëŒ€íšŒì˜ Wrap up Reportì´ì íšŒê³ ë¡ì…ë‹ˆë‹¤. ì² ì €í•œ <code>ê¸°ë¡</code>ê³¼ <code>ê³µìœ </code>ì— ê³µê°í•œ 7ëª…ì˜ íŒ€ì›ì´ ì²˜ìŒ í•©ì„ ë§ì¶”ì—ˆê¸° ë•Œë¬¸ì— ì–´ì„¤í”ˆ ì ë„ ìˆì—ˆì§€ë§Œ, ê·¸ê°„ì˜ ìƒìƒí•œ ê¸°ë¡ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì–´ë–»ê²Œ ì„œë¡œê°€ ì„œë¡œì˜ <code>ì…°ë¥´íŒŒ</code>ë¡œì¨ ë“±ë°˜ì„ ì™„ë£Œí•  ìˆ˜ ìˆì—ˆëŠ”ì§€ ì €í¬ì˜ ê²½í—˜ì„ ë‚˜ëˆ„ê³ ì í•©ë‹ˆë‹¤.</p><p>ë¬¼ë¡  ë¯¸í¡í•œ ì ë„ ìˆì—ˆê³ , ì—¬ëŸ¬ ì‹œí–‰ì°©ì˜¤ë¥¼ ê²ªì—ˆì§€ë§Œ ê²°ê³¼ì ìœ¼ë¡œëŠ” íŒ€ì› ëª¨ë‘ê°€ ë§Œì¡±í•œ í˜‘ì—…ì´ì—ˆë‹¤ëŠ” ì ì—ì„œ ì§€ë‚œ ëŒ€íšŒë³´ë‹¤ ë§ì€ ì„±ì¥ì„ í•  ìˆ˜ ìˆì—ˆë‹¤ê³  ëŠë‚„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì €í¬ì˜ ê²½í—˜ì´ ì–´ë– í•œ í˜•íƒœë¡œë“  ë„ì›€ì´ ë˜ê³ , ì¢‹ì€ ë ˆí¼ëŸ°ìŠ¤ê°€ ë˜ê¸°ë¥¼ ë°”ë¼ë©° ì‹œì‘í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p><br><p><strong>ëª©ì°¨</strong></p><ul><li><a href="#%E2%9A%94%EF%B8%8F-%ED%8C%80-%EC%86%8C%EA%B0%9C">íŒ€ì†Œê°œ</a><ul><li><a href="#%F0%9F%A4%9C-%EB%B6%80%EB%A1%9D-%ED%8C%80%EC%9B%90%EB%93%A4-%ED%95%9C%EB%A7%88%EB%94%94">ì²­ê³„ì‚°ì…°ë¥´íŒŒ</a></li><li><a href="#%F0%9F%91%A8%E2%80%8D%F0%9F%91%A8%E2%80%8D%F0%9F%91%A6%E2%80%8D%F0%9F%91%A6-%EC%B2%AD%EA%B3%84%EC%82%B0%EC%85%B0%EB%A5%B4%ED%8C%8C%EB%93%A4">ì²­ê³„ì‚°ì…°ë¥´íŒŒë“¤</a></li></ul></li><li><a href="#%F0%9F%94%8E-%EB%8C%80%ED%9A%8C-%EA%B0%9C%EC%9A%94">ëŒ€íšŒê°œìš”</a></li><li><a href="#%F0%9F%A4%9D-%ED%98%91%EC%97%85">í˜‘ì—…</a><ul><li><a href="#%F0%9F%A5%BE-%EC%82%AC%EC%A0%84%EB%85%BC%EC%9D%98">ì‚¬ì „ë…¼ì˜</a></li><li><a href="#%E2%9A%99%EF%B8%8F-%ED%98%91%EC%97%85%ED%88%B4">í˜‘ì—…íˆ´</a></li><li><a href="#%F0%9F%92%BB-%EC%BD%94%EB%93%9C-%EA%B4%80%EB%A6%AC">ì½”ë“œê´€ë¦¬</a></li><li><a href="#%F0%9F%A7%91%E2%80%8D%F0%9F%94%AC-%EC%B2%B4%EA%B3%84%EC%A0%81%EC%9D%B8-%EC%8B%A4%ED%97%98">ì²´ê³„ì ì¸ ì‹¤í—˜</a></li></ul></li><li><a href="#%F0%9F%9B%8B-Data-Experiments">Data Experiments</a><ul><li><a href="#%F0%9F%91%81-Data-EDA">Data EDA</a></li><li><a href="#%F0%9F%92%AA-Data-Augmentation">Data Augmentation</a></li><li><a href="#%F0%9F%94%A7-Data-Preprocessing-amp-Tokenizer">Data Preprocessing</a></li></ul></li><li><a href="#%F0%9F%A7%98-Modeling">Modeling</a></li><li><a href="#%F0%9F%8D%9C-Ensemble">Ensemble</a><ul><li><a href="#%F0%9F%91%A8%E2%80%8D%F0%9F%8E%A8-%EC%95%99%EC%83%81%EB%B8%94-%EA%B9%8E%EB%8A%94-%EB%85%B8%EC%9D%B8%EA%B3%BC-%EA%B8%B0%EB%8F%84%EB%A9%94%ED%83%80">ì•™ìƒë¸” ê¹ëŠ” ë…¸ì¸ê³¼ ê¸°ë„ë©”íƒ€</a></li></ul></li><li><a href="#%F0%9F%92%AF-Good-Practice">Good Practice</a></li><li><a href="#%F0%9F%92%8C-Thanks-to">Thanks to</a></li><li><a href="#%EB%A7%88%EC%A7%80%EB%A7%89%EC%9C%BC%EB%A1%9C">ë§ˆì§€ë§‰ìœ¼ë¡œ</a></li><li><a href="#%F0%9F%A4%9C-%EB%B6%80%EB%A1%9D-%ED%8C%80%EC%9B%90%EB%93%A4-%ED%95%9C%EB%A7%88%EB%94%94">ë¶€ë¡: íŒ€ì›ë“¤ í•œë§ˆë””</a></li></ul><h2 id="âš”ï¸-íŒ€-ì†Œê°œ"><a href="#âš”ï¸-íŒ€-ì†Œê°œ" class="headerlink" title="âš”ï¸ íŒ€ ì†Œê°œ"></a>âš”ï¸ íŒ€ ì†Œê°œ</h2><h3 id="â›°-ì²­ê³„ì‚°ì…°ë¥´íŒŒ"><a href="#â›°-ì²­ê³„ì‚°ì…°ë¥´íŒŒ" class="headerlink" title="â›° ì²­ê³„ì‚°ì…°ë¥´íŒŒ"></a>â›° ì²­ê³„ì‚°ì…°ë¥´íŒŒ</h3><p align="center">    <img src="/images/profile.png" style="display: inline" height="120px">    <img src="/images/2.png" style="display: inline" height="120px"></p><p>ì €í¬ëŠ” ìº í”„ ê¸°ê°„ë™ì•ˆ ëª¨ë“  ê²ƒì„ ìƒìƒí•˜ê²Œ ê¸°ì–µí•˜ê³  ë‚˜ëˆ„ëŠ” <code>ê¸°ë¡</code>ê³¼ <code>ê³µìœ </code>ë¼ëŠ” ê°€ì¹˜ì— ê³µê°í•œ 7ëª…ì´ ëª¨ì—¬ íŒ€ì„ êµ¬ì„±í–ˆê³ , ì„œë¡œê°€ ì„œë¡œì˜ ê°€ì´ë“œë¡œì„œ ì¢‹ì€ ì˜í–¥ì„ ì£¼ê³ ë°›ì„ ìˆ˜ ìˆëŠ” ì…°ë¥´íŒŒê°€ ë˜ê¸°ë¥¼ ì›í–ˆìŠµë‹ˆë‹¤.</p><p>Naverì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì‚°ì€ ì²­ê³„ì‚°ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì €í¬ëŠ” ì²­ê³„ì‚°ì„ ë“±ë°˜í•˜ë©° ìƒìƒí•˜ê²Œ ê¸°ë¡í•œ <code>ë“±ë°˜ì¼ì§€</code>ê°€ ì €í¬ë¥¼ ëª¨ì¼ ìˆ˜ ìˆê²Œ ë„ì™€ì¤€ ë„¤ì´ë²„ì— ë‹¿ì„ ìˆ˜ ìˆë„ë¡, <code>ì²­ê³„ì‚°ì…°ë¥´íŒŒ</code>ë¼ëŠ” ì´ë¦„ì„ ì‚¬ìš©í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.</p><h3 id="ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦-ì²­ê³„ì‚°ì…°ë¥´íŒŒë“¤"><a href="#ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦-ì²­ê³„ì‚°ì…°ë¥´íŒŒë“¤" class="headerlink" title="ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ì²­ê³„ì‚°ì…°ë¥´íŒŒë“¤"></a>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ì²­ê³„ì‚°ì…°ë¥´íŒŒë“¤</h3><ul><li>ì´ìš”í•œ</li><li>ë¬¸í•˜ê²¸</li><li>ì „ì¤€ì˜</li><li>ì •ì§„ì›</li><li>ê¹€ë¯¼ìˆ˜</li><li>ì •í¬ì˜</li><li>ê³½ì§„ì„±</li></ul><h2 id="ğŸ”-ëŒ€íšŒ-ê°œìš”"><a href="#ğŸ”-ëŒ€íšŒ-ê°œìš”" class="headerlink" title="ğŸ” ëŒ€íšŒ ê°œìš”"></a>ğŸ” ëŒ€íšŒ ê°œìš”</h2><p>ì´ë²ˆì— ì°¸ì—¬í•œ ëŒ€íšŒì˜ ê³¼ì œëŠ” ë¬¸ì¥ ë‚´ ê°œì²´ê°„ ê´€ê³„ ì¶”ì¶œ ê³¼ì œë¡œ, ë¬¸ì¥ì˜ ë‹¨ì–´(Entity)ì— ëŒ€í•œ ì†ì„±ê³¼ ê´€ê³„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ìì—°ì–´ ì²˜ë¦¬ ê³¼ì œì…ë‹ˆë‹¤. ê´€ê³„ ì¶”ì¶œì€ ë¹„êµ¬ì¡°ì ì¸ ìì—°ì–´ ë¬¸ì¥ì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë°ì— ëª©ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.</p><p>ì €í¬ê°€ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ì€ <a href="https://arxiv.org/pdf/2105.09680.pdf">ã€ŒKLUE: Korean Language Understanding Evaluationã€(Park et al., 2021)</a>ì„ í†µí•´ ê³µê°œëœ KLUE-RE ë°ì´í„°ì…‹ìœ¼ë¡œ, KLUE ë°ì´í„°ì…‹ì„ ì‚¬ì „í•™ìŠµí•œ RoBERTaë¥¼ fine-tuningí•˜ì—¬ ë² ì´ìŠ¤ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ì˜€ìœ¼ë©°, private leaderboardì—ì„œ f1 score ê¸°ì¤€ 19íŒ€ ì¤‘ 5ë“±, auprc ê¸°ì¤€ 19íŒ€ ì¤‘ 2ë“±ì„ ê¸°ë¡í•˜ì˜€ìŠµë‹ˆë‹¤.</p><p>ğŸ¥ˆ Final Score<br><img src="/images/final.png"></p><ul><li>micro F1 score: 73.732 (19íŒ€ ì¤‘ <strong>5ë“±</strong>)</li><li>AUPRC score: 82.964 (19íŒ€ ì¤‘ <strong>2ë“±</strong>)</li></ul><p><img src="/images/kakaotalk.png" alt="ë¬˜ë¹„ì•„ë‹˜"></p><h2 id="ğŸ¤-í˜‘ì—…"><a href="#ğŸ¤-í˜‘ì—…" class="headerlink" title="ğŸ¤ í˜‘ì—…"></a>ğŸ¤ í˜‘ì—…</h2><h3 id="ğŸ¥¾-ì‚¬ì „ë…¼ì˜"><a href="#ğŸ¥¾-ì‚¬ì „ë…¼ì˜" class="headerlink" title="ğŸ¥¾ ì‚¬ì „ë…¼ì˜"></a>ğŸ¥¾ ì‚¬ì „ë…¼ì˜</h3><p>RE ëŒ€íšŒê°€ ì‹œì‘í•˜ê¸° 1ì£¼ì¼ ì „ë¶€í„°, ì €í¬ëŠ” ë¯¸ë¦¬ ëŒ€íšŒë¥¼ ìœ„í•œ ì „ëµë“¤ì„ êµ¬ìƒí–ˆìŠµë‹ˆë‹¤. ì„œë¡œì˜ ìŠ¤íƒ€ì¼ì„ ëª¨ë¥´ê¸°ì— ë‹¹ì¥ì€ ê²°ì •ì´ ì•ˆë‚˜ë”ë¼ë„, ì„¸ë¶€ì ì¸ ì‚¬í•­ë“¤ì— ëŒ€í•œ ë…¼ì˜ë¥¼ ë‹¨ í•œë²ˆì´ë¼ë„ ê±°ì³¤ë˜ ê²ƒì€ ì¶”í›„ì— ì˜ì‚¬ê²°ì •ì†ë„ì™€ íŒ€ì›ë“¤ì˜ ë§Œì¡±ì— ìˆì–´ì„œ í° ì˜í–¥ì„ ë¼ì³¤ìŠµë‹ˆë‹¤.</p><details>    <summary>    ëŒ€íšŒ ì „ ë…¼ì˜ì‚¬í•­ë“¤    </summary><br><ul><li><p>í”„ë¡œì íŠ¸ê´€ë¦¬ íˆ´/ì±„ë„ ì •í•˜ê¸°</p><ul><li>ex) Github projectì˜ kanban board, notion, slack, zoom, google meet, git page, github action ë“±ë“±</li><li>ì¹´ì¹´ì˜¤í†¡ (ìŠ¬ë™ë³´ë‹¤ ë§ì´ ì ‘í•¨.) ìŠ¬ë™ì²˜ëŸ¼ ìŠ¤ë ˆë“œ í˜•ì‹ì˜ ëŒ€í™”ë¥¼ í•  ìˆ˜ ì—†ìŒ.<ul><li>ì¤‘ìš”í•œ ì´ìŠˆê°€ ìƒê¸°ë©´ ìŠ¬ë™ì—ë„ ê°™ì´ ì´ì•¼ê¸°í•˜ì.</li></ul></li></ul></li><li><p>ì½”ë“œëª…ì„¸ì„œ or ì»¨ë²¤ì…˜</p><ul><li>naming<ul><li>í´ë˜ìŠ¤, Static Vars = CamelCase</li><li>ë³€ìˆ˜ëª…, í•¨ìˆ˜ëª… = snake_case</li></ul></li><li>formatting (&amp; auto formatter)<ul><li>autopep8</li><li>black, yapâ€¦</li></ul></li><li>annotation<ul><li>â€˜â€™â€™ docstring â€˜â€™â€™</li><li>VSCODE CODE_ANCHORE<ul><li>TODO, NOTE,</li></ul></li><li>docstringì„ ì•Œì•„ì„œ í•´ì£¼ëŠ” ê²Œ ìˆëŠ”ì§€ ì„œì¹˜í•´ë³´ê¸°!</li><li>í•„ìš”í•œ ë‚´ìš©ë§Œ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ë£°ì„ ì¶”ê°€ë¡œ ì •í•  ê²ƒ.<br>ì£¼ì„ì€ ì˜ë¬¸ìœ¼ë¡œ!!</li></ul></li><li><del>indentation (tab 1 or space 4)</del></li><li>ê·¸ ì™¸ vscode extensions<ul><li>git graph, git lens</li><li>Live share</li></ul></li></ul></li><li><p>ê°€ìƒí™˜ê²½ì´ë‚˜ í™˜ê²½ê´€ë¦¬ ì „ëµ (zsh, dotenv, â€¦ conda, pip â€¦)</p><ul><li><strong>conda ì‚¬ìš©!</strong></li></ul></li><li><p><strong>ë¯¸ì •</strong></p><ul><li>ë¸Œëœì¹˜ë¥¼ ì–´ë–»ê²Œ ë§Œë“¤ì–´ë†“ì„ê²ƒì¸ê°€ (ì‹¤í—˜ì „ëµê¹Œì§€ ê³ ë ¤)<br>  ë‹¤ë¥¸ì‚¬ëŒë“¤ì´ checkoutë§Œìœ¼ë¡œ ë™ì¼í•œ ì‹¤í—˜ì„ í•  ìˆ˜ ìˆê²Œ í•˜ê¸° ìœ„í•¨<br>  MAIN<ul><li>DEVELOP<pre><code>  ìœ ì €í¸ì˜ì„±, ì½”ë“œê¸°ëŠ¥ê°œì„ , ë²„ê·¸í”½ìŠ¤  ì ‘ë‘ì–´/feature</code></pre></li><li>BASELINE<br>  ì ‘ë‘ì–´/feature x ì‹¤í—˜ o<br>ë‹¤ë¥¸ íƒœìŠ¤í¬ì— ëŒ€í•œ ê²ƒë“¤ì´ë‚˜ (ì‹¤í—˜ìœ„ì£¼)<br>  baseline/qa/1<br>  baseline/ner<br>  baseline/sentence classification</li></ul></li><li>ë„ˆë¬´ ë¸Œëœì¹˜ê°€ ë§ì•„ì§ˆ ìˆ˜ ìˆë‹¤.<ul><li>configë¥¼ ë³€ê²½í•˜ë©´ ë¸Œëœì¹˜ë¥¼ ë¶„ê¸°í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤.</li></ul></li></ul></li><li><p>(ì„ íƒì‚¬í•­) ì—¬ìœ ê°€ ë˜ë©´ ìì„¸í•˜ê²Œ ì¨ë†“ê¸°</p></li><li><p>ì»¤ë°‹ì „ëµ</p><ul><li>commit message ê·œì¹™ì´ë‚˜ í…œí”Œë¦¿ ì •í•˜ê¸°</li></ul></li><li><p>(ì‘ì—…ë‹¨ìœ„ì™€ ë¦¬ë·°ì— ëŒ€í•´ì„œ ë” ìƒê°í•´ë³´ê¸°)</p></li><li><p>PR í…œí”Œë¦¿ ë° PR/Review ì „ëµ êµ¬ì²´í™”</p><ul><li>PR ì˜¬ë¦¬ëŠ” íƒ€ì´ë°(ì‹œì )<ul><li>ì„±ëŠ¥í–¥ìƒì— ì˜í•œ PRì€ ëª¨ë‘ê°€ ë¦¬ë·°</li><li>ìì˜í•œ ë³€í™”ë“¤ì€ ì±…ì„ìë§Œ ë¦¬ë·°</li></ul></li><li>ë¦¬ë·°ë¥¼ ì–´ë–»ê²Œ í•  ê±´ì§€? ë¦¬ë·°ì–´ëŠ” ëª‡ ëª…</li><li>ì†ë„? Mergeì†ë„ì— ëŒ€í•´ì„œ ë°ë“œë¼ì¸ì´ ìˆì—ˆìŒ ì¢‹ê² ë‹¤.</li></ul></li><li><p>ê·¸ë¼ìš´ë“œë£° ë° ë¹ ë¥¸ ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ í˜‘ì—…ê°€ì¹˜ ë¦¬ìŠ¤íŠ¸ì—… ë° ìš°ì„ ìˆœìœ„ ì •í•˜ê¸°</p><ul><li>ex) ì•ˆì •ì„±(ì˜ˆì™¸ì²˜ë¦¬), êµ¬ì„±ì›ì˜ë§Œì¡±, ê°€ë…ì„±, ì¼ê´€ì„±, ê°ì²´ì§€í–¥ì„±, ë‹¨ìˆœì„±, ì™¸ë¶€ìœ ì €ì˜ê²½í—˜, ì‹ ì†ì„±(ì‘ì—…ì†ë„), í†µì œê°€ëŠ¥ì„±, í•™ìŠµê°€ëŠ¥ì„±, ì·¨ì—…ì ìš©ê°€ëŠ¥ì„±, ì‹¤í—˜ê°€ëŠ¥ì„± ë“±ë“±</li></ul></li></ul></details><p>ë˜í•œ ì´ëŸ¬í•œ ì‚¬ì „ë…¼ì˜ë¥¼ í†µí•´ ëŒ€íšŒê°€ ì§„í–‰ë ìˆ˜ë¡ íŒ€ì›ë“¤ì´ ë¬´ì—‡ì„ ì›í•˜ëŠ”ì§€ í™•ì‹¤íˆ ì•Œ ìˆ˜ ìˆì—ˆìœ¼ë©°, ëª¨ë‘ê°€ ê°™ì€ ê·¸ë¦¼ì„ ê·¸ë¦¬ê³  ê°™ì€ ë°©í–¥ì„ ê°€ì§€ê³  ëŒ€íšŒì— ì„í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p><p>ì´ëŸ¬í•œ ë…¸ë ¥ì„ í† ëŒ€ë¡œ ì €í¬ëŠ” ë¹ˆí‹ˆì—†ì´ ê¸°ë¡ì„ ì´ì–´ê°€ê³ , ì‹¤í—˜ì„ ê³µìœ í•˜ë©° í•­ìƒ ìƒˆë¡œìš´ ì‹¤í—˜ì•„ì´ë””ì–´ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼ í•˜ë£¨ì— 10ë²ˆì”© ì œì¶œê°€ëŠ¥í•œ ëŒ€íšŒì—ì„œ 12ì¼ ë™ì•ˆ ë‹¤ë¥¸ íŒ€ë“¤ ëŒ€ë¹„ ì••ë„ì ì¸ íšŸìˆ˜ì¸ <em><strong>99ë²ˆì˜ ì‹¤í—˜ê²°ê³¼ë¥¼ ì œì¶œ</strong></em> í•´ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p><h3 id="âš™ï¸-í˜‘ì—…íˆ´"><a href="#âš™ï¸-í˜‘ì—…íˆ´" class="headerlink" title="âš™ï¸ í˜‘ì—…íˆ´"></a>âš™ï¸ í˜‘ì—…íˆ´</h3><p>ì§€ë‚œ ëŒ€íšŒ ë•Œ ë‹¤ì–‘í•œ í˜‘ì—… ì±„ë„ì„ êµ¬ì„±í•˜ì˜€ì„ ë•Œ ì˜¤íˆë ¤ í˜¼ë€ì´ ê°€ì¤‘ë˜ê³  ëª¨ë“  ì±„ë„ì„ ì‚¬ìš©í•˜ê¸° í˜ë“¤ë‹¤ëŠ” ì ì„ ê³ ë ¤í•˜ì—¬, ëŒ€ë¶€ë¶„ì˜ í˜‘ì—…ì„ <code>Notion</code>ìœ¼ë¡œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ë˜í•œ ë¶ˆê°€í”¼í•œ ìƒí™©ì— ëŒ€ë¹„í•œ ì—°ë½ìˆ˜ë‹¨ìœ¼ë¡œ <code>kakaotalk</code>ê³¼ <code>slack</code>ì„ ì‚¬ìš©í•˜ì˜€ê³ , <code>git</code>ì€ ì‚¬ìš©ê°€ëŠ¥í•œ ê¸°ëŠ¥ì„ ìµœì†Œí•œìœ¼ë¡œ í•˜ê³  ì½”ë“œê´€ë¦¬ ìˆ˜ë‹¨ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.</p><p><code>Notion</code>ì—ì„œ ì¼ì •ê´€ë¦¬, ë¬¸ì„œê´€ë¦¬, ì‹¤í—˜ê´€ë¦¬ ë“± ë§ì€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì—„ë°€í•˜ê²Œ Templateì„ ì°¾ì•„ë³´ë©° Dashboardë¥¼ êµ¬ì„±í•˜ì˜€ê³  ê·¸ë ‡ê²Œ ì•„ë˜ì™€ ê°™ì€ í˜ì´ì§€ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p><p align="center">    <img src="/images/notion_main.png" style="display: inline" height="220px" width="32%">    <img src="/images/notion_kanban.png" style="display: inline" height="220px" width="32%">    <img src="/images/notion_schedule.png" style="display: inline" height="220px" width="32%"></p><p><strong>Main Dashboard</strong></p><ul><li><p>sub pageë“¤ì˜ linkì™€ zoom, wandb, github, drive ë§í¬ë“¤</p></li><li><p>TODOì™€ ì‹¤í—˜ê´€ë¦¬ë¥¼ ìœ„í•œ kanban ë³´ë“œ</p><ul><li><p>ì‹¤í—˜ì„ ìœ„í•œ Processë³„ Tag ë¶€ì°©</p>  <img src="/images/no_tag.png" height="30%" width="30%"></li><li><p>Assignee í• ë‹¹</p></li></ul></li><li><p>ì¼ì •ê´€ë¦¬ë¥¼ ìœ„í•œ schedule</p><ul><li>ì•Œë¦¼ê¸°ëŠ¥ í™œì„±í™”</li><li>ìš©ë„ë³„ Tag ë¶€ì°©</li></ul></li><li><p>Referenceì™€ Docs ë§í¬ë“¤</p><ul><li>íšŒì˜ë¡</li><li>ë©˜í† ë§</li><li>ì—°êµ¬ì¼ì§€ ë“±</li></ul></li></ul><h3 id="ğŸ’»-ì½”ë“œ-ê´€ë¦¬"><a href="#ğŸ’»-ì½”ë“œ-ê´€ë¦¬" class="headerlink" title="ğŸ’» ì½”ë“œ ê´€ë¦¬"></a>ğŸ’» ì½”ë“œ ê´€ë¦¬</h3><p><img src="/images/git1.png"></p><p>ì´ˆë°˜ì—ëŠ” ì „ì²´ ì½”ë“œë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•´ PR-Merge ë°©ë²•ìœ¼ë¡œ ì§„í–‰í•˜ë‹¤ê°€ Reviewê°€ ëŠ¦ì–´ì§€ê±°ë‚˜, ì‘ì—…ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¬ë©´ ë‹¤ë¥¸ íŒ€ì›ì´ ê°™ì€ ì‘ì—…ì„ í•˜ëŠ” ë“± ì˜ˆìƒì¹˜ ëª»í•œ ë³‘ëª©ì´ ë°œìƒí•˜ê³  ì˜¤íˆë ¤ ê°œì¸ ì‹¤í—˜ì— ë°©í•´ìš”ì†Œë¡œ ì‘ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” íŒë‹¨ì„ í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.</p><style>  .linear_highlight {      background: linear-gradient(to top, #778899 10%, transparent 10%);  }</style><span class="linear_highlight">ë”°ë¼ì„œ baselineìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì½”ë“œì—ì„œ ê°ìì˜ ì´ë¦„ í˜¹ì€ ì‹¤í—˜ ì´ë¦„ìœ¼ë¡œ ë¶„ê¸°ë¥¼ ë‚˜ëˆ„ì–´ ê°œì¸ ì‘ì—…ì„ ì§„í–‰í•˜ë©´ì„œ, ì‚¬ì „ì— ë…¼ì˜í–ˆë˜ ê²ƒì²˜ëŸ¼ scoreê°€ ì˜¬ëì„ ê²½ìš°ì—ë§Œ baseline ì½”ë“œì— PR-Mergeë¥¼ í•˜ê³ , í•´ë‹¹ scoreë¥¼ ì¬í˜„ê°€ëŠ¥í•  ìˆ˜ ìˆê²Œë” ë²„ì „ì—…í•˜ê¸°ë¡œ í–ˆìŠµë‹ˆë‹¤.</span><p><img src="/images/bran.png"></p><p>branchê°€ ë§ì•„ì§€ê¸´ í–ˆì§€ë§Œ, ì‹¤í—˜ì— ì‹¤íŒ¨í–ˆì„ ë•Œ ë¹ ë¥´ê²Œ Rollbackí•  ìˆ˜ ìˆì—ˆê³ , ê°ìì˜ ì‹¤í—˜ì—ì„œ í™•ì‹¤í•œ ì„±ëŠ¥í–¥ìƒ ìš”ì†Œë§Œì„ í•©ì¹  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. Competitionì´ë¼ëŠ” í”Œë«í¼ì˜ íŠ¹ì„±ìƒ 7ëª…ì˜ íŒ€ì›ì´ ê°ì ì‘ì„±í•œ ëª¨ë“  ì½”ë“œë“¤ì„ Reviewí•˜ê³  í•©ì¹˜ë©´ì„œ ì‘ì—…ì„ ì´ì–´ë‚˜ê°€ê¸°ì—ëŠ” ë§ì€ ì‹œê°„ê³¼ ë…¸ë ¥ì„ í•„ìš”ë¡œ í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ê¸°ì¤€ì„ ë‘ê³  í•„ìš”í•  ë•Œë§Œ ì½”ë“œë¥¼ ë³‘í•©í•˜ë‹ˆ ì‹¤í—˜ì€ ì‹¤í—˜ëŒ€ë¡œ ì˜ ì´ë£¨ì–´ì§€ê³ , ì‹¤í—˜ì— ì‹¤íŒ¨í•˜ë”ë¼ë„ ê°€ì¥ ìµœì‹ ë²„ì „ì˜ ì½”ë“œë¥¼ ëª¨ë‘ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆì—ˆë‹¤ëŠ” ì ì—ì„œ ë§ì€ ì´ì ì„ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p><h3 id="ğŸ§‘â€ğŸ”¬-ì²´ê³„ì ì¸-ì‹¤í—˜"><a href="#ğŸ§‘â€ğŸ”¬-ì²´ê³„ì ì¸-ì‹¤í—˜" class="headerlink" title="ğŸ§‘â€ğŸ”¬ ì²´ê³„ì ì¸ ì‹¤í—˜"></a>ğŸ§‘â€ğŸ”¬ ì²´ê³„ì ì¸ ì‹¤í—˜</h3><p><img src="/images/notion_kanban.png"></p><p>ì €í¬ëŠ” Kanban boardë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜ì„ ê´€ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.</p><p align="center">    <img src="/images/exp_tag.png" height="30%" width="30%"></p><p>Backlog, TO-DO, In progress, Completed ë„¤ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì„œë¡œê°€ ì–´ë–¤ ì‹¤í—˜ì„ ì§„í–‰í•˜ê³  ìˆëŠ”ì§€, ì–´ë–¤ ì‹¤í—˜ì„ í•´ì•¼í•˜ëŠ”ì§€ íŒŒì•…í•  ìˆ˜ ìˆê²Œ í•˜ì˜€ìœ¼ë©° ì‹¤í—˜ì´ ëë‚  ë•Œë§ˆë‹¤ ê·¸ë•Œê·¸ë•Œ ê°±ì‹ í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.</p><p>ê°ê°ì˜ ì¹´í…Œê³ ë¦¬ ë³„ ì±…ì„ì€ ì´ë ‡ìŠµë‹ˆë‹¤.</p><ul><li>Backlog: ë‹¨ìˆœ ì‹¤í—˜ ì•„ì´ë””ì–´ ë° ê±´ì˜ì‚¬í•­, ìˆ˜ì •ì‚¬í•­</li><li>TO-DO: ê¼­ ì ìš©í•´ë´ì•¼ í•˜ëŠ” ì‹¤í—˜</li><li>In progress: í˜„ì¬ ì§„í–‰ì¤‘ì¸ ì‹¤í—˜</li><li>Completed: ì™„ë£Œëœ ì‹¤í—˜</li></ul><p>Backlogì— ì§„í–‰í•´ë³´ê³  ì‹¶ì€ ì‹¤í—˜ì¹´ë“œê°€ ìƒê²¼ê±°ë‚˜, ë‹¤ë¥¸ ì‹¤í—˜ ì•„ì´ë””ì–´ê°€ ìƒê¸´ ê²½ìš°ì—ëŠ” Notionì˜ <code>Comment</code> ê¸°ëŠ¥ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ ì§„í–‰ì¤‘ì¸ ì‹¤í—˜ì´ë©´ í•´ë‹¹ ì‹¤í—˜ì˜ ì§„í–‰ìƒí™©ì´ë‚˜ ì£¼ì˜ì‚¬í•­ë“¤ì„ ë” ìì„¸í•˜ê²Œ ê³µìœ í•  ìˆ˜ ìˆê²Œ í•˜ì˜€ìŠµë‹ˆë‹¤.</p><p align="center">    <img src="/images/notion_comm2.png">    <img src="/images/notion_comm.png"></p><p>ì‹¤í—˜ì¹´ë“œê°€ <code>Completed</code>ë¡œ ì´ë™í•˜ê²Œ ë˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì‹¤í—˜ê¸°ë¡í‘œì— ê²°ê³¼ë¥¼ ì‘ì„±í•˜ê³ , ì‹¤í—˜ì˜ ì„±ê³µì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ê·¸ ì‹¤í—˜ì— ëŒ€í•œ í‰ê°€ì™€ ê·¸ëŸ° ê²°ê³¼ê°€ ë‚˜ì˜¨ ì´ìœ  í˜¹ì€ ì£¼ì˜ì‚¬í•­ ë“±ì„ ê¸°ë¡í•˜ê²Œ í•˜ì˜€ìŠµë‹ˆë‹¤.</p><p align="center">    <img src="/images/exp1.png">    <img src="/images/notion_exp.png"></p><span class="linear_highlight">ì´ëŸ¬í•œ ì‹œë„ëŠ” íŒ€ì›ë“¤ ê°„ ê¸°ìˆ ë¶€ì±„ë¥¼ ìµœëŒ€í•œ ì¤„ì–´ë“¤ê²Œ í•˜ì˜€ê³  ì‹¤íŒ¨í•œ ì‹¤í—˜ì„ ë°˜ë³µì ìœ¼ë¡œ í•˜ì§€ ì•Šì„ ìˆ˜ ìˆê²Œ í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í—˜ì„ ê³„íší•  ìˆ˜ ìˆê²Œ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.</span><h2 id="ğŸ›‹-Data-Experiments"><a href="#ğŸ›‹-Data-Experiments" class="headerlink" title="ğŸ›‹ Data Experiments"></a>ğŸ›‹ Data Experiments</h2><h3 id="ğŸ‘-Data-EDA"><a href="#ğŸ‘-Data-EDA" class="headerlink" title="ğŸ‘ Data EDA"></a>ğŸ‘ Data EDA</h3><p><img src="/images/eda.png"></p><p>ë°ì´í„°ëŠ” ìœ„ì™€ ê°™ì´ ë§¤ìš° ë¶ˆê· í˜•í•˜ê²Œ ë¶„í¬ë˜ì–´ ìˆì—ˆê³ , 9,000ê°œê°€ ë„˜ëŠ” no_relationê³¼ ë‹¬ë¦¬ <code>per:place_of_death</code>ì²˜ëŸ¼ ì•½ 40ê°œ ì •ë„ë§Œ ì¡´ì¬í•˜ëŠ” labelë„ ìˆì—ˆìŠµë‹ˆë‹¤.</p><p>ì´ë ‡ê²Œ ê·¹ë‹¨ì ì¸ Data Imbalancingì„ ì˜ ì¡ëŠ” ê²ƒì´ ì´ë²ˆ ëŒ€íšŒì˜ í•µì‹¬ì´ì—ˆìŠµë‹ˆë‹¤.</p><p><img src="/images/dup.png" alt="ê¹€ì±„ì€ ìº í¼ë‹˜ì˜ í† ë¡ ê²Œì‹œíŒ ê¸€ ì¤‘"></p><p>ë˜í•œ sentenceì™€ subject_entity, object_entityê¹Œì§€ ì „ë¶€ ë™ì¼í•œ ë¬¸ì¥ì´ 53ê°œê°€ ìˆëŠ” ë“± ì¤‘ë³µëœ ë°ì´í„°ì™€ mislabeled ë°ì´í„°ë“¤ì´ ì¡´ì¬í•˜ì˜€ê³ , ì´ê²ƒë“¤ì„ ì „ë¶€ ì œê±°í•˜ê³  ìˆ˜ì •í•˜ì—¬ ë°ì´í„°ì…‹ì„ ì¬êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.</p><h3 id="ğŸ’ª-Data-Augmentation"><a href="#ğŸ’ª-Data-Augmentation" class="headerlink" title="ğŸ’ª Data Augmentation"></a>ğŸ’ª Data Augmentation</h3><p>ì´í›„ì—ëŠ” Data Imbalancingì„ í•´ê²°í•˜ê¸° ìœ„í•˜ì—¬ ì—¬ëŸ¬ Augmentation ê¸°ë²•ë“¤ë¡œ ì‹¤í—˜ì„ ì´ì–´ë‚˜ê°”ìŠµë‹ˆë‹¤.</p><ol><li><p><a href="https://github.com/toriving/KoEDA">EDA &amp; AEDA</a><br> KoEDA ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ EDA, AEDA ê°ê° ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ <code>n_aug=[1, 2, 4]</code> ë¹„ìœ¨ë¡œ augmentation ì§„í–‰</p><ul><li>ë‘ ë°©ë²• ëª¨ë‘ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•Šì•˜ì„ ë•Œë³´ë‹¤ validation scoreê°€ ë‚®ì•˜ìŒ.</li></ul></li><li><p><a href="https://imbalanced-learn.org/stable/">Undersampling &amp; Oversampling</a><br> imblearn ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ SMOTEë¡œ Sampling ì§„í–‰<br> <img src="/images/under.png" alt="Undersampling"></p><p> <img src="/images/over.png" alt="Oversampling"></p><ul><li>ë‘ ë°©ë²• ëª¨ë‘ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•Šì•˜ì„ ë•Œë³´ë‹¤ validation scoreê°€ ë‚®ì•˜ìŒ.</li></ul></li><li><p>Back Translation<br> Crawlerë¥¼ ì‚¬ìš©í•˜ì—¬ papago ë²ˆì—­ê¸° ì‚¬ìš©.<br> <code>klue/roberta-small</code> ëª¨ë¸ ê¸°ì¤€ìœ¼ë¡œ score ìƒìŠ¹ì´ ìˆì—ˆì§€ë§Œ ë„ˆë¬´ ëŠ¦ê²Œ ì‹œë„í•´ì„œ best ëª¨ë¸ì— ì ìš©í•˜ì§€ ëª»í–ˆìŒ.</p><ul><li><code>ko -&gt; en -&gt; ja -&gt; ko</code>: ì•½ 0.1 LB Score í•˜ë½</li><li><code>ko -&gt; ja -&gt; ko</code>: ì•½ 0.5 LB Score ìƒìŠ¹</li></ul></li><li><p>Target Augmentation subject &lt;-&gt; object label changing<br> kfoldë¡œ í•™ìŠµì„ ì§„í–‰í•  ë•Œ í•œ ë²ˆì´ë¼ë„ í‹€ë¦° dataì— ëŒ€í•´ì„œ subjectì™€ object entityë¥¼ ë³€ê²½í•¨ìœ¼ë¡œì¨ augmentation ì§„í–‰</p><ul><li>ì•½ 0.05 LB Score ìƒìŠ¹</li></ul></li></ol><p>í•˜ì§€ë§Œ ì´ëŸ¬í•œ augmentation ê¸°ë²•ë“¤ì— ëŒ€í•´ì„œ ë§ì€ íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ê°€ ì—†ì—ˆëŠ”ë°, <code>confusion matrix</code>ë¥¼ í†µí•´ ì›ì¸ì„ ìœ ì¶”í•´ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p><p><img src="/images/conf.png"></p><p>ì²˜ìŒ ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ì ì€ labelì˜ ë°ì´í„°ë¥¼ ìƒê°ë³´ë‹¤ ì˜ ë§ì¶”ê³  ìˆì—ˆê³ , <em>ì˜¤íˆë ¤ ë°ì´í„° ìˆ˜ê°€ ê°€ì¥ ë§ì•˜ë˜ <code>no_relation</code> ì˜ˆì¸¡ì—ì„œ ë§ì´ í‹€ë¦¬ê³  ìˆì—ˆê¸° ë•Œë¬¸</em> ì´ì—ˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œ augmentationì„ ì§„í–‰í•œ ë°©ì‹, ê·¸ë¦¬ê³  sampling ë°©ì‹ìœ¼ë¡œëŠ” íš¨ê³¼ë¥¼ ë³´ì§€ ëª»í–ˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p><p>ì²˜ìŒë¶€í„° ì´ë ‡ê²Œ Confusion Matrixë¥¼ ë„ì…í•˜ì—¬ í˜„ì¬ ëª¨ë¸ì´ ì–´ë–¤ ì˜ˆì¸¡ì„ ì˜ ìˆ˜í–‰í•˜ì§€ ëª»í•˜ëŠ”ì§€ ë“±ì„ íŒŒì•…í•˜ì—¬, <code>no_relation</code>ì— ëŒ€í•´ì„œë§Œ augmentationì„ ì‹œë„í•˜ëŠ” ë“± ë””í…Œì¼í•˜ê²Œ augmentation ì „ëµì„ ì„¸ì› ìœ¼ë©´ ì¢‹ì•˜ì„ ê²ƒì´ë€ ì•„ì‰¬ì›€ì´ ë‚¨ìŠµë‹ˆë‹¤. ë˜í•œ 4ë²ˆ ì‹¤í—˜ì—ì„œ <code>sub &lt;-&gt; obj</code> labelë§Œ ë³€ê²½í•˜ëŠ” ë°©ì‹ ë§ê³  ë‹¤ë¥¸ augmentation ë°©ë²•ë„ ì¨ë´¤ìœ¼ë©´ ì–´ë• ì„ê¹Œ í•˜ëŠ” ì•„ì‰¬ì›€ì´ ë‚¨ìŠµë‹ˆë‹¤.</p><h3 id="ğŸ”§-Data-Preprocessing-amp-Tokenizer"><a href="#ğŸ”§-Data-Preprocessing-amp-Tokenizer" class="headerlink" title="ğŸ”§ Data Preprocessing &amp; Tokenizer"></a>ğŸ”§ Data Preprocessing &amp; Tokenizer</h3><ol><li><p>Dynamic Padding<br> Huggingfaceì˜ TokenizerëŠ” <code>max_length</code> ì¸ìë¥¼ í†µí•´ ê¸°ë³¸ì ìœ¼ë¡œ <code>fixed padding</code> ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì €í¬ëŠ” ë” ë¹ ë¥¸ ì‹¤í—˜ì„ í†µí•´ <code>dynamic padding</code> ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•˜ì˜€ê³  ê·¸ ê²°ê³¼ ì•½ 30%ì˜ ì†ë„ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p><p> <img src="/images/fixed.png" alt="fixed padding"></p><p> <img src="/images/dynamic.png" alt="dynamic padding"></p></li><li><p><a href="https://arxiv.org/pdf/2102.01373.pdf">An Improved Baseline for Sentence-level Relation Extraction</a><br> ë¬¸ì¥ì˜ Subject, Object Entityì˜ NER Typeì„ ëª…ì‹œí•´ì£¼ê³ , Entityì˜ ìœ„ì¹˜ë¥¼ ì‚¬ì „í•™ìŠµì—ì„œ ì‚¬ìš©ëœ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì´ìš©í•˜ì—¬ í‘œê¸°í•˜ëŠ” Typed Entity Markerë¥¼ ì ìš©í–ˆìŠµë‹ˆë‹¤.</p><p> <img src="/images/token.png"></p><ol><li>vanilla : ê¸°ë³¸ ë² ì´ìŠ¤ë¼ì¸ input</li><li>special_ent : <code>ê¸°ë³¸ ë² ì´ìŠ¤ë¼ì¸ input + [sbj][sbj/] + [obj][obj/]</code></li><li>special_ent_without_prefix : ê¸°ë³¸ ë² ì´ìŠ¤ë¼ì¸ inputì˜ ì•ì—ìˆëŠ” <code>subject [sep] object [sep] ë¶€ë¶„ì„ ì œê±°</code>í•˜ê³  <code>special token</code>ì„ ì‚¬ìš© (4, 5ë²ˆ ì—­ì‹œ prefixë¥¼ ì œê±°í•¨) </li><li>punct_ent : <code>@sbj@ #obj#</code> ì‹ìœ¼ë¡œ special token ì—†ì´ entity í‘œí˜„ </li><li>punct_typing_ent : <code>@*sbj_type*sbj@ #^obj_type^obj#</code> ì‹ìœ¼ë¡œ entity typeì„ ì•Œë ¤ì£¼ë©° í‘œí˜„ê²°ê³¼: 3ë²ˆ 5ë²ˆì´ ë¹„êµì  ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„, ë™ì¼ ì¡°ê±´ í•˜ validation f1 ê¸°ì¤€ 1 ì •ë„ì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë³´ì„.</li></ol></li></ol><p>ìœ„ì˜ ë‘ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜ê³¼ ê²€ì¦ì€ ì¡°ê¸ˆ ë” ë¹ ë¥´ê²Œ ì§„í–‰í•  ìˆ˜ ìˆì—ˆê³ , ì„±ëŠ¥ í–¥ìƒì„ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p><h2 id="ğŸ§˜-Modeling"><a href="#ğŸ§˜-Modeling" class="headerlink" title="ğŸ§˜ Modeling"></a>ğŸ§˜ Modeling</h2><p>Backboneì´ ë˜ëŠ” Modelì€ <code>klue/roberta-large</code>ë¥¼ ì‚¬ìš©í•˜ì˜€ìœ¼ë©° Base ì„±ëŠ¥ì€ <code>avg. 71 (micro f1)</code> ì •ë„ë¥¼ ê¸°ë¡í•˜ì˜€ìŠµë‹ˆë‹¤.</p><p><em><strong>ì—¬ëŸ¬ê°€ì§€ ì‹¤í—˜ë“¤</strong></em></p><ul><li><p>Entity Embedding<br>  ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•Šì•˜ì„ ë•Œë³´ë‹¤ validation scoreê°€ ë‚®ì•˜ìŒ.</p><details>  <summary>  ì½”ë“œ ë³´ê¸°  </summary>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RobertaEmbeddingsWithTokenEmbedding</span>(<span class="hljs-params">nn.Module</span>):</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">edit by ê³½ì§„ì„±_T2011</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, model, config, pre_model_state_dict=<span class="hljs-literal">None</span></span>):</span><br>    <span class="hljs-built_in">super</span>().__init__()<br>    self.word_embeddings = model.roberta.embeddings.word_embeddings<br>    self.position_embeddings = model.roberta.embeddings.position_embeddings<br>    self.token_type_embeddings = model.roberta.embeddings.token_type_embeddings<br><br>    self.entity_embeddings = nn.Embedding(<span class="hljs-number">9</span>, config.hidden_size, padding_idx=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">if</span> pre_model_state_dict:<br>        pre_weight = pre_model_state_dict[<span class="hljs-string">&#x27;roberta.embeddings.entity_embeddings.weight&#x27;</span>]<br>        self.entity_embeddings.weight = torch.nn.parameter.Parameter(pre_weight, requires_grad=<span class="hljs-literal">True</span>)<br><br>    self.LayerNorm = model.roberta.embeddings.LayerNorm<br>    self.dropout = model.roberta.embeddings.dropout<br>    self.position_embedding_type = <span class="hljs-built_in">getattr</span>(config, <span class="hljs-string">&quot;position_embedding_type&quot;</span>, <span class="hljs-string">&quot;absolute&quot;</span>)<br>    self.register_buffer(<span class="hljs-string">&quot;position_ids&quot;</span>, torch.arange(config.max_position_embeddings).expand((<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)))<br>    <span class="hljs-keyword">if</span> version.parse(torch.__version__) &gt; version.parse(<span class="hljs-string">&quot;1.6.0&quot;</span>):<br>        self.register_buffer(<br>            <span class="hljs-string">&quot;token_type_ids&quot;</span>,<br>            torch.zeros(self.position_ids.size(), dtype=torch.long, device=self.position_ids.device),<br>            persistent=<span class="hljs-literal">False</span>,<br>        )<br>    self.padding_idx = config.pad_token_id<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params"></span></span><br><span class="hljs-params"><span class="hljs-function">    self, input_ids=<span class="hljs-literal">None</span>, token_type_ids=<span class="hljs-literal">None</span>, position_ids=<span class="hljs-literal">None</span>, inputs_embeds=<span class="hljs-literal">None</span>, past_key_values_length=<span class="hljs-number">0</span></span></span><br><span class="hljs-params"><span class="hljs-function"></span>):</span><br>    <span class="hljs-keyword">if</span> position_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">if</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            position_ids = self.create_position_ids_from_input_ids(input_ids, self.padding_idx, past_key_values_length)<br>        <span class="hljs-keyword">else</span>:<br>            position_ids = self.create_position_ids_from_inputs_embeds(inputs_embeds)<br><br>    <span class="hljs-keyword">if</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        input_shape = input_ids.size()<br>    <span class="hljs-keyword">else</span>:<br>        input_shape = inputs_embeds.size()[:-<span class="hljs-number">1</span>]<br><br>    seq_length = input_shape[<span class="hljs-number">1</span>]<br><br>    <span class="hljs-keyword">if</span> token_type_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(self, <span class="hljs-string">&quot;token_type_ids&quot;</span>):<br>            buffered_token_type_ids = self.token_type_ids[:, :seq_length]<br>            buffered_token_type_ids_expanded = buffered_token_type_ids.expand(input_shape[<span class="hljs-number">0</span>], seq_length)<br>            token_type_ids = buffered_token_type_ids_expanded<br>        <span class="hljs-keyword">else</span>:<br>            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)<br><br>    <span class="hljs-keyword">if</span> inputs_embeds <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        inputs_embeds = self.word_embeddings(input_ids)<br>    token_type_embeddings = self.token_type_embeddings(token_type_ids)<br><br>    entity_ids = self.create_entity_ids_from_input_ids(input_ids)<br>    entity_embeddings = self.entity_embeddings(entity_ids)<br><br>    embeddings = inputs_embeds + token_type_embeddings<br>    <span class="hljs-keyword">if</span> self.position_embedding_type == <span class="hljs-string">&quot;absolute&quot;</span>:<br>        position_embeddings = self.position_embeddings(position_ids)<br>        embeddings += position_embeddings<br>    <br>    embeddings += entity_embeddings<br>    <br>    embeddings = self.LayerNorm(embeddings)<br>    embeddings = self.dropout(embeddings)<br>    <span class="hljs-keyword">return</span> embeddings<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_position_ids_from_inputs_embeds</span>(<span class="hljs-params">self, inputs_embeds</span>):</span><br>    input_shape = inputs_embeds.size()[:-<span class="hljs-number">1</span>]<br>    sequence_length = input_shape[<span class="hljs-number">1</span>]<br><br>    position_ids = torch.arange(<br>        self.padding_idx + <span class="hljs-number">1</span>, sequence_length + self.padding_idx + <span class="hljs-number">1</span>, dtype=torch.long, device=inputs_embeds.device<br>    )<br>    <span class="hljs-keyword">return</span> position_ids.unsqueeze(<span class="hljs-number">0</span>).expand(input_shape)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_entity_ids_from_input_ids</span>(<span class="hljs-params">self, input_ids</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    map index 1~8 to the token that is related to sbj, obj entities</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    s_ids = torch.nonzero((input_ids == <span class="hljs-number">36</span>)) <span class="hljs-comment"># subject</span><br>    o_ids = torch.nonzero((input_ids == <span class="hljs-number">7</span>)) <span class="hljs-comment"># object</span><br>    <span class="hljs-comment"># entity type mapped into index 3 ~ 8</span><br>    type_map = &#123;<span class="hljs-number">4410</span> : <span class="hljs-number">3</span>, <span class="hljs-number">7119</span> : <span class="hljs-number">4</span>, <span class="hljs-number">3860</span> : <span class="hljs-number">5</span>, <span class="hljs-number">5867</span> : <span class="hljs-number">6</span>, <span class="hljs-number">12395</span> : <span class="hljs-number">7</span>, <span class="hljs-number">9384</span> : <span class="hljs-number">8</span>&#125;<br><br>    entity_ids = torch.zeros_like(input_ids)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s_ids)):<br>        s_id = s_ids[i]<br>        o_id = o_ids[i]<br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:<br>            entity_ids[s_id[<span class="hljs-number">0</span>], s_id[<span class="hljs-number">1</span>]+<span class="hljs-number">2</span>] = type_map[input_ids[s_id[<span class="hljs-number">0</span>], s_id[<span class="hljs-number">1</span>]+<span class="hljs-number">2</span>].item()]<br>            entity_ids[o_id[<span class="hljs-number">0</span>], o_id[<span class="hljs-number">1</span>]+<span class="hljs-number">2</span>] = type_map[input_ids[o_id[<span class="hljs-number">0</span>], o_id[<span class="hljs-number">1</span>]+<span class="hljs-number">2</span>].item()]<br>        <span class="hljs-keyword">else</span>:<br>            prev_s_id = s_ids[i-<span class="hljs-number">1</span>]<br>            prev_o_id = o_ids[i-<span class="hljs-number">1</span>]<br>            entity_ids[s_id[<span class="hljs-number">0</span>], prev_s_id[<span class="hljs-number">1</span>]+<span class="hljs-number">4</span>:s_id[<span class="hljs-number">1</span>]] = <span class="hljs-number">1</span><br>            entity_ids[o_id[<span class="hljs-number">0</span>], prev_o_id[<span class="hljs-number">1</span>]+<span class="hljs-number">4</span>:o_id[<span class="hljs-number">1</span>]] = <span class="hljs-number">2</span><br><br>    <span class="hljs-keyword">return</span> entity_ids<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_position_ids_from_input_ids</span>(<span class="hljs-params">self, input_ids, padding_idx, past_key_values_length=<span class="hljs-number">0</span></span>):</span><br>    mask = input_ids.ne(padding_idx).<span class="hljs-built_in">int</span>()<br>    incremental_indices = (torch.cumsum(mask, dim=<span class="hljs-number">1</span>).type_as(mask) + past_key_values_length) * mask<br>    <span class="hljs-keyword">return</span> incremental_indices.long() + padding_idx<br></code></pre></td></tr></table></figure></details></li><li><p><a href="https://github.com/monologg/R-BERT">R-BERT</a><br>  ë³¸ êµ¬ì¡°ì—ì„œ BERTë¥¼ RoBERTaë¡œ ë³€ê²½. LB ê¸°ì¤€ 71.362ì˜ micro f1 score ë‹¬ì„±.</p><details>  <summary>  ì½”ë“œ ë³´ê¸°  </summary>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RBERT</span>(<span class="hljs-params">RobertaPreTrainedModel</span>):</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    orgin code: https://github.com/monologg/R-BERT</span><br><span class="hljs-string">    edit by ë¬¸í•˜ê²¸_T2076</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config, model_name</span>):</span><br>        <span class="hljs-built_in">super</span>(RBERT, self).__init__(config)<br>        self.roberta = RobertaModel.from_pretrained(<br>            model_name)  <span class="hljs-comment"># Load pretrained bert</span><br><br>        self.num_labels = config.num_labels<br><br>        self.cls_fc_layer = FCLayer(<br>            config.hidden_size, config.hidden_size, <span class="hljs-number">0.1</span>)<br>        self.entity_fc_layer = FCLayer(<br>            config.hidden_size, config.hidden_size, <span class="hljs-number">0.1</span>)<br>        self.label_classifier = FCLayer(<br>            config.hidden_size * <span class="hljs-number">3</span>,<br>            config.num_labels,<br>            <span class="hljs-number">0.1</span>,<br>            use_activation=<span class="hljs-literal">False</span>,<br>        )<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">entity_average</span>(<span class="hljs-params">hidden_output, e_mask</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Average the entity hidden state vectors (H_i ~ H_j)</span><br><span class="hljs-string">        :param hidden_output: [batch_size, j-i+1, dim]</span><br><span class="hljs-string">        :param e_mask: [batch_size, max_seq_len]</span><br><span class="hljs-string">                e.g. e_mask[0] == [0, 0, 0, 1, 1, 1, 0, 0, ... 0]</span><br><span class="hljs-string">        :return: [batch_size, dim]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        e_mask_unsqueeze = e_mask.unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># [b, 1, j-i+1]</span><br>        length_tensor = (e_mask != <span class="hljs-number">0</span>).<span class="hljs-built_in">sum</span>(<br>            dim=<span class="hljs-number">1</span>).unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># [batch_size, 1]</span><br><br>        <span class="hljs-comment"># [b, 1, j-i+1] * [b, j-i+1, dim] = [b, 1, dim] -&gt; [b, dim]</span><br>        sum_vector = torch.bmm(e_mask_unsqueeze.<span class="hljs-built_in">float</span>(),<br>                               hidden_output).squeeze(<span class="hljs-number">1</span>)<br>        avg_vector = sum_vector.<span class="hljs-built_in">float</span>() / length_tensor.<span class="hljs-built_in">float</span>()  <span class="hljs-comment"># broadcasting</span><br>        <span class="hljs-keyword">return</span> avg_vector<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, input_ids=<span class="hljs-literal">None</span>, attention_mask=<span class="hljs-literal">None</span>, token_type_ids=<span class="hljs-literal">None</span>, labels=<span class="hljs-literal">None</span>, e1_mask=<span class="hljs-literal">None</span>, e2_mask=<span class="hljs-literal">None</span></span>):</span><br>        outputs = self.roberta(<br>            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)<br>        sequence_output = outputs[<span class="hljs-number">0</span>]<br>        pooled_output = outputs[<span class="hljs-number">1</span>]<br><br>        <span class="hljs-comment"># Average</span><br>        e1_h = self.entity_average(sequence_output, e1_mask)<br>        e2_h = self.entity_average(sequence_output, e2_mask)<br><br>        <span class="hljs-comment"># Dropout -&gt; tanh -&gt; fc_layer (Share FC layer for e1 and e2)</span><br>        pooled_output = self.cls_fc_layer(pooled_output)<br>        e1_h = self.entity_fc_layer(e1_h)<br>        e2_h = self.entity_fc_layer(e2_h)<br><br>        <span class="hljs-comment"># Concat -&gt; fc_layer</span><br>        concat_h = torch.cat([pooled_output, e1_h, e2_h], dim=-<span class="hljs-number">1</span>)<br>        logits = self.label_classifier(concat_h)<br><br>        <span class="hljs-comment"># add hidden states and attention if they are here</span><br>        outputs = (logits,) + outputs[<span class="hljs-number">2</span>:]<br><br>        <span class="hljs-comment"># Softmax</span><br>        <span class="hljs-keyword">if</span> labels <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">if</span> self.num_labels == <span class="hljs-number">1</span>:<br>                loss_fct = nn.MSELoss()<br>                loss = loss_fct(logits.view(-<span class="hljs-number">1</span>), labels.view(-<span class="hljs-number">1</span>))<br>            <span class="hljs-keyword">else</span>:<br>                loss_type = <span class="hljs-string">&quot;focal&quot;</span><br>                beta = <span class="hljs-number">0.9999</span><br>                gamma = <span class="hljs-number">2.0</span><br><br>                loss_fct = CB_loss(beta=beta, gamma=gamma)<br>                loss = loss_fct(logits.view(-<span class="hljs-number">1</span>, self.num_labels),<br>                                labels.view(-<span class="hljs-number">1</span>), loss_type)<br><br>            outputs = (loss,) + outputs<br>        <span class="hljs-keyword">return</span> outputs<br></code></pre></td></tr></table></figure></details></li><li><p>Model split &amp; combine<br>  <code>no_relation</code>ë§Œ êµ¬ë¶„í•˜ë„ë¡ í•™ìŠµì‹œí‚¨ ëª¨ë¸, <code>relation</code>ë§Œ êµ¬ë¶„í•˜ë„ë¡ í•™ìŠµì‹œí‚¨ ëª¨ë¸, <code>ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµì‹œí‚¨ ëª¨ë¸</code> ì„¸ ê°€ì§€ <code>klue/roberta-large</code> ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ freezing í•˜ê³  classifierë§Œ í•™ìŠµì‹œí‚¨ ê²ƒ. LB ê¸°ì¤€ 73.251ì˜ micro f1 score ë‹¬ì„±.</p>  <details>      <summary>      ì½”ë“œ ë³´ê¸°      </summary>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CombineModels</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    edit by ì´ìš”í•œ_T2166</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(CombineModels, self).__init__()<br><br>        c1 = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;klue/roberta-large&#x27;</span>, num_labels=<span class="hljs-number">2</span>)<br>        c2 = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;klue/roberta-large&#x27;</span>, num_labels=<span class="hljs-number">29</span>)<br>        c3 = AutoConfig.from_pretrained(<span class="hljs-string">&#x27;klue/roberta-large&#x27;</span>, num_labels=<span class="hljs-number">30</span>)<br><br>        self.roberta1 = AutoModelForSequenceClassification.from_pretrained(<br>            <span class="hljs-string">&quot;split_model_no_rel_large&quot;</span>, config=c1)<br>        self.roberta2 = AutoModelForSequenceClassification.from_pretrained(<br>            <span class="hljs-string">&quot;split_model_rel_large&quot;</span>, config=c2)<br>        self.roberta3 = AutoModelForSequenceClassification.from_pretrained(<br>            <span class="hljs-string">&quot;sota_kfold&quot;</span>, config=c3)<br><br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.roberta1.parameters():<br>            p.requires_grad = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.roberta2.parameters():<br>            p.requires_grad = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.roberta3.parameters():<br>            p.requires_grad = <span class="hljs-literal">False</span><br><br>        self.fc1 = nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">768</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">29</span>, <span class="hljs-number">768</span>)<br>        self.fc3 = nn.Linear(<span class="hljs-number">30</span>, <span class="hljs-number">768</span>)<br><br>        self.classifier = nn.Sequential(<br>            nn.Dropout(p=<span class="hljs-number">0.1</span>),<br>            nn.Linear(<span class="hljs-number">768</span> * <span class="hljs-number">15</span>, <span class="hljs-number">768</span>, bias=<span class="hljs-literal">True</span>),<br>            nn.Tanh(),<br>            nn.Dropout(p=<span class="hljs-number">0.1</span>),<br>            nn.Linear(<span class="hljs-number">768</span>, <span class="hljs-number">30</span>, bias=<span class="hljs-literal">True</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, input_ids, attention_mask</span>):</span><br>        logits_1 = self.roberta1(<br>            input_ids.clone(), attention_mask=attention_mask).get(<span class="hljs-string">&#x27;logits&#x27;</span>)<br>        logits_2 = self.roberta2(<br>            input_ids.clone(), attention_mask=attention_mask).get(<span class="hljs-string">&#x27;logits&#x27;</span>)<br>        logits_3 = self.roberta3(<br>            input_ids.clone(), attention_mask=attention_mask).get(<span class="hljs-string">&#x27;logits&#x27;</span>)<br><br>        logits_1 = self.fc1(logits_1)<br>        logits_2 = self.fc2(logits_2)<br>        logits_3 = self.fc1(logits_3)<br><br>        concatenated_vectors = torch.cat((<br>            logits_1, logits_2, logits_3), dim=-<span class="hljs-number">1</span>)<br><br>        output = self.classifier(concatenated_vectors)<br>        outputs = SequenceClassifierOutput(logits=output)<br>        <span class="hljs-keyword">return</span> outputs<br></code></pre></td></tr></table></figure>  </details></li><li><p>FC Layer -&gt; LSTM<br>  ë„ˆë¬´ ëŠ¦ê²Œ ë„ì…í•˜ì—¬ ì œì¶œ ì‹¤íŒ¨.</p><details>  <summary>  ì½”ë“œ ë³´ê¸°  </summary>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RobertaAddLSTM</span>(<span class="hljs-params">RobertaPreTrainedModel</span>):</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    edit by ì •í¬ì˜_T2210</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config, *args, **kwargs</span>):</span><br>            <span class="hljs-built_in">super</span>().__init__(config=config)<br><br>            self.bert = RobertaModel.from_pretrained(<span class="hljs-string">&quot;klue/roberta-large&quot;</span>)<br><br>            self.lstm = nn.LSTM(<span class="hljs-number">1024</span>, <span class="hljs-number">256</span>, batch_first=<span class="hljs-literal">True</span>, bidirectional=<span class="hljs-literal">True</span>)<br>            self.linear = nn.Linear(<span class="hljs-number">256</span>*<span class="hljs-number">2</span>, <span class="hljs-number">30</span>)<br>            self.dropout = nn.Dropout(<span class="hljs-number">0.5</span>)<br>            self.tanh = nn.Tanh()<br>            self.linear2 = nn.Linear(<span class="hljs-number">30</span>, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, input_ids, attention_mask</span>):</span><br>            output = self.bert(input_ids, attention_mask=attention_mask)<br><br>            lstm_output, (h,c) = self.lstm(output[<span class="hljs-number">0</span>]) <span class="hljs-comment">## extract the 1st token&#x27;s embeddings</span><br>            hidden = torch.cat((lstm_output[:,-<span class="hljs-number">1</span>, :<span class="hljs-number">256</span>],lstm_output[:,<span class="hljs-number">0</span>, <span class="hljs-number">256</span>:]),dim=-<span class="hljs-number">1</span>)<br>            linear_output = self.linear(hidden.view(-<span class="hljs-number">1</span>,<span class="hljs-number">256</span>*<span class="hljs-number">2</span>))<br>            x = self.tanh(linear_output)<br>            x = self.dropout(x)<br>            outputs = SequenceClassifierOutput(logits=x)<br><br>            <span class="hljs-keyword">return</span> outputs<br></code></pre></td></tr></table></figure></details></li><li><p>TAPT - <a href="https://arxiv.org/pdf/2004.10964.pdf">Donâ€™t Stop Pretraining: Adapt Language Models to Domains and Tasks</a><br>  ì£¼ì–´ì§„ í•™ìŠµë°ì´í„°ë¡œ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì— TAPT ë¥¼ ì ìš©í•´ë³´ì•˜ì„ ë•Œ ì•½ 0.5 ì •ë„ì˜ validation f1 score í–¥ìƒì´ ìˆì—ˆìœ¼ë‚˜, ì‹œê°„ë¬¸ì œë¡œ ë…¼ë¬¸ì—ì„œ ì œì•ˆëœ epochsë§Œí¼ í•™ìŠµì„ ì§„í–‰í•˜ì§€ ëª»í–ˆìŒ. koelectraì™€ roberta-baseë¡œ ë¦¬ë”ë³´ë“œì— ì œì¶œí•´ë³¸ ê²°ê³¼ í° ì„±ëŠ¥í–¥ìƒì´ ì—†ì—ˆê¸° ë•Œë¬¸ì— large ëª¨ë¸ì— ì ìš©í•´ë³¼ ìˆ˜ ì—†ì—ˆìŒ.</p>  <details>      <summary>      ì½”ë“œ ë³´ê¸°      </summary>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">edit by ì •ì§„ì›_T2206</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, RobertaForMaskedLM, ElectraForMaskedLM, BertForMaskedLM, AutoConfig, DataCollatorWithPadding, DataCollatorForLanguageModeling<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> LineByLineTextDataset<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer, TrainingArguments<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> EarlyStoppingCallback<br><br><span class="hljs-comment"># fetch pretrained model for MaskedLM training </span><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;klue/roberta-large&#x27;</span>)<br>device = torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>)<br>model = BertForMaskedLM.from_pretrained(<span class="hljs-string">&#x27;klue/roberta-large&#x27;</span>)<br>model.to(device)<br><br><span class="hljs-comment"># Read txt file which is consisted of sentences from train.csv</span><br>dataset = LineByLineTextDataset(<br>    tokenizer=tokenizer,<br>    file_path=<span class="hljs-string">&#x27;data/train.txt&#x27;</span>,<br>    block_size=<span class="hljs-number">514</span> <span class="hljs-comment"># block size needs to be modified to max_position_embeddings</span><br>)<br><br>data_collator = DataCollatorForLanguageModeling( <br>    tokenizer=tokenizer, mlm=<span class="hljs-literal">True</span>, mlm_probability=<span class="hljs-number">0.2</span> <br>)<br><br><span class="hljs-comment"># need to change arguments </span><br>training_args = TrainingArguments(<br>    output_dir=<span class="hljs-string">&quot;./klue-roberta-retrained&quot;</span>,<br>    overwrite_output_dir=<span class="hljs-literal">True</span>,<br>    learning_rate=<span class="hljs-number">5e-05</span>,<br>    num_train_epochs=<span class="hljs-number">200</span>, <br>    per_device_train_batch_size=<span class="hljs-number">16</span>,<br>    save_steps=<span class="hljs-number">100</span>,<br>    save_total_limit=<span class="hljs-number">2</span>,<br>    seed=<span class="hljs-number">30</span>,<br>    save_strategy=<span class="hljs-string">&#x27;epoch&#x27;</span>,<br>    gradient_accumulation_steps=<span class="hljs-number">8</span>,<br>    logging_steps=<span class="hljs-number">100</span>,<br>    evaluation_strategy=<span class="hljs-string">&#x27;epoch&#x27;</span>,<br>    resume_from_checkpoint=<span class="hljs-literal">True</span>,<br>    fp16=<span class="hljs-literal">True</span>,<br>    fp16_opt_level=<span class="hljs-string">&#x27;O1&#x27;</span>,<br>    load_best_model_at_end=<span class="hljs-literal">True</span><br>) <br><br>trainer = Trainer(<br>    model=model,<br>    args=training_args,<br>    data_collator=data_collator,<br>    train_dataset=dataset,<br>    eval_dataset=dataset,<br>    callbacks = [EarlyStoppingCallback(early_stopping_patience=<span class="hljs-number">3</span>)]<br>)<br><br>trainer.train()<br>trainer.save_model(<span class="hljs-string">&quot;./klue-roberta-retrained&quot;</span>)<br></code></pre></td></tr></table></figure>  </details></li></ul><p><em><strong>loss function</strong></em></p><ul><li><p>CB Loss<br>  R-BERTë¥¼ ì œì™¸í•˜ê³ ëŠ” í° ì„±ëŠ¥í–¥ìƒì„ ëª»ë´¤ìŒ.</p>  <details>      <summary>      ì½”ë“œ ë³´ê¸°      </summary>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyTrainer</span>(<span class="hljs-params">Trainer</span>):</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    edit by ë¬¸í•˜ê²¸_T2076</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, disable_wandb=<span class="hljs-literal">True</span>, *args, **kwargs</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__(*args, **kwargs)<br>        self.disable_wandb = disable_wandb<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_loss</span>(<span class="hljs-params">self, model, inputs, return_outputs=<span class="hljs-literal">False</span></span>):</span><br>        labels = inputs.get(<span class="hljs-string">&quot;labels&quot;</span>)<br>        outputs = model(**inputs)<br>        logits = outputs.get(<span class="hljs-string">&quot;logits&quot;</span>)<br>        beta = <span class="hljs-number">0.9999</span><br>        gamma = <span class="hljs-number">2.0</span><br><br>        criterion = CB_loss(beta, gamma)<br>        <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>            criterion.cuda()<br>        loss_fct = criterion(logits, labels)<br><br>        <span class="hljs-keyword">return</span> (loss_fct, outputs) <span class="hljs-keyword">if</span> return_outputs <span class="hljs-keyword">else</span> loss_fct<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evaluation_loop</span>(<span class="hljs-params">self, *args, **kwargs</span>):</span><br>        eval_loop_output = <span class="hljs-built_in">super</span>().evaluation_loop(*args, **kwargs)<br><br>        pred = eval_loop_output.predictions<br>        label_ids = eval_loop_output.label_ids<br><br>        self.draw_confusion_matrix(pred, label_ids)<br>        <span class="hljs-keyword">return</span> eval_loop_output<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CB_loss</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, beta, gamma, epsilon=<span class="hljs-number">0.1</span></span>):</span><br>        <span class="hljs-built_in">super</span>(CB_loss, self).__init__()<br>        self.beta = beta<br>        self.gamma = gamma<br>        self.epsilon = epsilon<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, logits, labels</span>):</span><br>        <span class="hljs-comment"># self.epsilon = 0.1 #labelsmooth</span><br>        beta = self.beta<br>        gamma = self.gamma<br><br>        no_of_classes = logits.shape[<span class="hljs-number">1</span>]<br>        samples_per_cls = torch.Tensor(<br>            [<span class="hljs-built_in">sum</span>(labels == i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(logits.shape[<span class="hljs-number">1</span>])])<br>        <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>            samples_per_cls = samples_per_cls.cuda()<br><br>        effective_num = <span class="hljs-number">1.0</span> - torch.<span class="hljs-built_in">pow</span>(beta, samples_per_cls)<br>        weights = (<span class="hljs-number">1.0</span> - beta) / ((effective_num) + <span class="hljs-number">1e-8</span>)<br><br>        weights = weights / torch.<span class="hljs-built_in">sum</span>(weights) * no_of_classes<br>        labels = labels.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br><br>        weights = torch.tensor(weights.clone().detach()).<span class="hljs-built_in">float</span>()<br><br>        <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>            weights = weights.cuda()<br>            labels_one_hot = torch.zeros(<br>                <span class="hljs-built_in">len</span>(labels), no_of_classes).cuda().scatter_(<span class="hljs-number">1</span>, labels, <span class="hljs-number">1</span>).cuda()<br><br>        labels_one_hot = (<span class="hljs-number">1</span> - self.epsilon) * labels_one_hot + \<br>            self.epsilon / no_of_classes<br>        weights = weights.unsqueeze(<span class="hljs-number">0</span>)<br>        weights = weights.repeat(labels_one_hot.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>) * labels_one_hot<br>        weights = weights.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>)<br>        weights = weights.unsqueeze(<span class="hljs-number">1</span>)<br>        weights = weights.repeat(<span class="hljs-number">1</span>, no_of_classes)<br><br>        cb_loss = focal_loss(labels_one_hot, logits, weights, gamma)<br>        <span class="hljs-keyword">return</span> cb_loss<br></code></pre></td></tr></table></figure>  </details></li><li><p><a href="https://arxiv.org/pdf/1906.07413.pdf">LDAM</a></p>  <details>      <summary>      ì½”ë“œ ë³´ê¸°      </summary>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LDAMLossTrainer</span>(<span class="hljs-params">Trainer</span>):</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    edit by ê¹€ë¯¼ìˆ˜_T2025</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, *args, **kwargs</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__(*args, **kwargs)<br>        self.n_per_labels = self.train_dataset.get_n_per_labels()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_loss</span>(<span class="hljs-params">self, model, inputs, return_outputs=<span class="hljs-literal">False</span></span>):</span><br>        labels = inputs.get(<span class="hljs-string">&#x27;labels&#x27;</span>)<br>        outputs = model(**inputs)<br>        logits = outputs.get(<span class="hljs-string">&#x27;logits&#x27;</span>)<br><br>        betas = [<span class="hljs-number">0</span>, <span class="hljs-number">0.99</span>]<br>        beta_idx = self.state.epoch &gt;= <span class="hljs-number">2</span><br>        n_per_labels = self.n_per_labels<br><br>        effective_num = <span class="hljs-number">1.0</span> - np.power(betas[beta_idx], n_per_labels)<br>        cls_weights = (<span class="hljs-number">1.0</span> - betas[beta_idx]) / np.array(effective_num)<br>        cls_weights = cls_weights / np.<span class="hljs-built_in">sum</span>(cls_weights) * <span class="hljs-built_in">len</span>(n_per_labels)<br>        cls_weights = torch.FloatTensor(cls_weights)<br><br>        criterion = LDAMLoss(cls_num_list=n_per_labels, max_m=<span class="hljs-number">0.5</span>, s=<span class="hljs-number">30</span>, weight=cls_weights)<br>        <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>            criterion.cuda()<br><br>        loss_fct = criterion(logits, labels)<br>        <span class="hljs-keyword">return</span> (loss_fct, outputs) <span class="hljs-keyword">if</span> return_outputs <span class="hljs-keyword">else</span> loss_fct<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LDAMLoss</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, cls_num_list, max_m=<span class="hljs-number">0.5</span>, weight=<span class="hljs-literal">None</span>, s=<span class="hljs-number">30</span></span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        m_list = <span class="hljs-number">1.0</span> / np.sqrt(np.sqrt(cls_num_list))<br>        m_list = m_list * (max_m / np.<span class="hljs-built_in">max</span>(m_list))<br>        m_list = torch.cuda.FloatTensor(m_list)<br>        self.m_list = m_list<br>        <span class="hljs-keyword">assert</span> s &gt; <span class="hljs-number">0</span><br>        self.s = s<br>        self.weight = weight<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x, target</span>):</span><br>        index = torch.zeros_like(x, dtype=torch.<span class="hljs-built_in">bool</span>)<br>        index.scatter_(<span class="hljs-number">1</span>, target.data.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), <span class="hljs-number">1</span>)<br><br>        index_float = index.<span class="hljs-built_in">type</span>(torch.cuda.FloatTensor)<br>        batch_m = torch.matmul(self.m_list[<span class="hljs-literal">None</span>, :], index_float.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br>        batch_m = batch_m.view((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        x_m = x - batch_m<br><br>        output = torch.where(index, x_m, x)<br>        <span class="hljs-keyword">return</span> F.cross_entropy(self.s * output.to(<span class="hljs-string">&#x27;cuda&#x27;</span>), target.to(<span class="hljs-string">&#x27;cuda&#x27;</span>), weight=self.weight.to(<span class="hljs-string">&#x27;cuda&#x27;</span>))<br></code></pre></td></tr></table></figure>  </details></li></ul><p>ê²°ê³¼ì ìœ¼ë¡  backbone ëª¨ë¸ì˜ kfold scoreë¥¼ ë„˜ì–´ì„œì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê·¸ ì´ìœ ë¡œëŠ” public leaderboardì™€ ê°„ê·¹ì´ ì ì€ ì ì ˆí•œ validation datasetì„ êµ¬ì„±í•˜ì§€ ëª»í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. </p><p>ì°¨ì„ ì±…ìœ¼ë¡œ ë¯¸ë¦¬ stratifiedí•˜ê²Œ 0.1 ë¹„ìœ¨ë¡œ splití•œ train, validation datasetì„ ê³ ì •ì‹œì¼œë†“ê³  ì‚¬ìš©í•˜ì˜€ì§€ë§Œ, í•´ë‹¹ ë°ì´í„°ì…‹ì˜ validation scoreëŠ” public leaderboardì™€ <em><strong>í‰ê· ì ìœ¼ë¡œ 15ì  ì´ìƒ, ê·¹ë‹¨ì ì¸ ê²½ìš° 30ì ê¹Œì§€ ì°¨ì´ê°€ ì¡´ì¬</strong></em> í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ validation datasetìœ¼ë¡œë§Œ ì‹¤í—˜ì„ í–ˆê¸° ë•Œë¬¸ì— validation scoreë¥¼ ì‹ ë¢°í•˜ê¸° ì–´ë ¤ì› ê³ , modelì´ ì¢‹ì€ì§€ ë‚˜ìœì§€ ì§ì ‘ ì œì¶œí•´ë³´ê¸° ì „ì—ëŠ” ì•Œ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.</p><p>ë”°ë¼ì„œ ì œì¶œíšŸìˆ˜ê°€ í•œì •ì ì´ë¯€ë¡œ ëŒ€ë¶€ë¶„ ìœ„ì˜ validation scoreë¡œë§Œ ê²€ì¦ì„ í–ˆê³ , ì„±ëŠ¥í–¥ìƒ ê°€ëŠ¥ì„±ì´ ì—†ë‹¤ê³  íŒë‹¨í•´ ì¶”ê°€ì ì¸ ì‹¤í—˜ì„ ì§„í–‰í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë§‰ìƒ 1, 2ë“±ì˜ solutionì„ ë³´ë‹ˆ ì €í¬ê°€ ì§„í–‰í–ˆë˜ ì‹¤í—˜ë“¤ë¡œ ì ìˆ˜ë¥¼ ì˜¬ë ¸ê¸°ì— ì†ì´ ì“°ë ¸ìŠµë‹ˆë‹¤â€¦ :(</p><p>ë‹¤ìŒ ëŒ€íšŒì—ì„œëŠ” public leaderboardì™€ì˜ ê°„ê·¹ì´ ì ì€ ì ì ˆí•œ validation datasetì„ êµ¬ì„±í•  í•„ìš”ê°€ ìˆìœ¼ë©°, ë˜í•œ êµì°¨ê²€ì¦ì„ ìœ„í•œ validation dataset ì—­ì‹œ ê³ ì •ì‹œì¼œë†“ì„ í•„ìš”ê°€ ìˆë‹¤ê³  ëŠê¼ˆìŠµë‹ˆë‹¤.</p><h2 id="ğŸœ-Ensemble"><a href="#ğŸœ-Ensemble" class="headerlink" title="ğŸœ Ensemble"></a>ğŸœ Ensemble</h2><ul><li><p>K-fold</p><p>  <code>klue/roberta-large</code> ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ kfold(k=5)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•˜ì˜€ìŠµë‹ˆë‹¤. single fold ê¸°ì¤€ public leaderboardì—ì„œ ì•½ 71ì˜ micro f1 scoreë¥¼ ê¸°ë¡í•˜ì˜€ê³ , 5 fold ensembleì„ í†µí•´ public leaderboardì—ì„œ 73.5ì˜ micro f1 scoreë¥¼ ê¸°ë¡í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p></li></ul><h3 id="ğŸ‘¨â€ğŸ¨-ì•™ìƒë¸”-ê¹ëŠ”-ë…¸ì¸ê³¼-ê¸°ë„ë©”íƒ€"><a href="#ğŸ‘¨â€ğŸ¨-ì•™ìƒë¸”-ê¹ëŠ”-ë…¸ì¸ê³¼-ê¸°ë„ë©”íƒ€" class="headerlink" title="ğŸ‘¨â€ğŸ¨ ì•™ìƒë¸” ê¹ëŠ” ë…¸ì¸ê³¼ ê¸°ë„ë©”íƒ€"></a>ğŸ‘¨â€ğŸ¨ ì•™ìƒë¸” ê¹ëŠ” ë…¸ì¸ê³¼ ê¸°ë„ë©”íƒ€</h3><p><img src="/images/soft_voting.jpg" alt="soft voting"></p><p>ìµœì¢…ì ìœ¼ë¡œ public leaderboard ê¸°ì¤€ 73 ì •ë„ì˜ micro f1 scoreë¥¼ ê¸°ë¡í•˜ì˜€ì§€ë§Œ ì˜ˆì¸¡ ë¶„í¬ê°€ ë‹¤ë¥¸ ê²°ê³¼ë“¤ì„ <code>soft voting</code>í•˜ì—¬ public leaderboard ê¸°ì¤€ 74.306ì˜ micro f1 scoreë¥¼ ê¸°ë¡í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p><p align="center">    <img src="/images/ê¸°ë„1.png" style="display: inline" height="100px">    <img src="/images/ê¸°ë„2.png" style="display: inline" height="100px">    <img src="/images/ê¸°ë„3.png" style="display: inline" height="100px">    <img src="/images/ê¸°ë„4.png" style="display: inline" height="100px"></p><p align="center">    <img src="/images/ê¸°ë„5.png" height="100px"></p><p>    ìµœì¢…ì ìœ¼ë¡œ ì œì¶œëœ ê²°ê³¼ëŠ” Ensembleëœ ê²ƒë“¤ ì¤‘ public leaderboard ê¸°ì¤€ AUPRCê°€ ê°€ì¥ ë†’ì€ ê²°ê³¼ì´ë©°, private leaderboard ì—ì„œ ë‹¤ë¥¸ íŒ€ ëŒ€ë¹„ ì ìˆ˜ í•˜ë½í­ì´ ì ì–´ì„œ     <span class="linear_highlight">    ìˆœìœ„ê°€ 9ë“± -> 5ë“±ìœ¼ë¡œ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤.    </span></p><p><img src="/images/final.png"></p><h2 id="ğŸ’¯-Good-Practice"><a href="#ğŸ’¯-Good-Practice" class="headerlink" title="ğŸ’¯ Good Practice"></a>ğŸ’¯ Good Practice</h2><p>ì €í¬ íŒ€ë§Œì˜ Good PracticeëŠ” ì²´ê³„ì ìœ¼ë¡œ Notionì— ì‹¤í—˜ê´€ë¦¬ë¥¼ í•œ ê²ƒë„ ìˆì§€ë§Œ, <code>huggingface</code>ì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ë“¤ì„ ì‚¬ìš©í•´ë´¤ë‹¤ëŠ” ê²ƒì´ê³  ê·¸ ì¤‘ì—ì„œ ì¢‹ì€ íš¨ê³¼ë¥¼ ë‚¸ ê²ƒìœ¼ë¡œëŠ” <code>fp16</code>ê³¼ <code>hyperparameter_search</code>ê°€ ìˆìŠµë‹ˆë‹¤.</p><ul><li><p>fp16</p><p>  <img src="/images/fp16.png"><br>  fp16ì€ <code>Mixed-Precision Training</code>ìœ¼ë¡œ 32-bit Floating Pointê°€ ì•„ë‹Œ 16-bit Floating Pointë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì´ ë°©ì‹ì„ í†µí•´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ë•Œ ì„±ëŠ¥ì€ ë¹„ìŠ·í•˜ì§€ë§Œ ì•½ 60% ê°€ëŸ‰ì˜ í–¥ìƒëœ ì†ë„ë¡œ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.<br>  <code>TrainingArguments</code>ì— <code>fp16=True</code>, <code>fp16_opt_level=&#39;O1&#39;</code>ë§Œ ì¶”ê°€í•˜ë©´ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ì„œ ê°„ë‹¨í•˜ê²Œ ë‹¤ì–‘í•œ ì‹¤í—˜ì„ ì§„í–‰í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p></li></ul><ul><li><p>hyperparameter_search</p><p>  <code>hyperparameter_search</code>ëŠ” <code>Trainer</code>ì— ì¡´ì¬í•˜ëŠ” methodë¡œ <code>raytune</code>, <code>optuna</code>, <code>SigOpt</code> ì„¸ ê°€ì§€ ì¤‘ ìì‹ ì˜ í™˜ê²½ì— ì„¤ì¹˜ë˜ì–´ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ì ì ˆí•œ hyperparameterë¥¼ íƒìƒ‰í•´ì£¼ëŠ” ìœ ìš©í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤. ì €í¬ëŠ” <code>hyperparameter_search</code>ë¡œ public leaderboard ê¸°ì¤€ 4ì  ì´ìƒì˜ f1 score í–¥ìƒì„ ê¸°ë¡í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p>  <details>      <summary>      ì½”ë“œ ë³´ê¸°      </summary>      <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification, AutoConfig, AutoTokenizer, Trainer, TrainingArguments<br><br><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> load your tokenizer &amp; dataset</span><br><span class="hljs-comment"># tokenizer = ...</span><br><span class="hljs-comment"># dataset = ...</span><br><br><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> change your pretrained model path</span><br>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;YOUR_MODEL_PATH&quot;</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model_init</span>():</span><br>    <span class="hljs-keyword">return</span> AutoModelForSequenceClassification.from_pretrained(<br>        model_path, config=config)<br><br><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> fill it your training arguments</span><br>training_args = TrainingArguments(...)<br><br><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> fill it your trainer arguments</span><br>trainer = Trainer(<br>    model_init=model_init, <span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> ë°˜ë“œì‹œ model_init í•¨ìˆ˜ë¡œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì•¼í•©ë‹ˆë‹¤.</span><br>    args=training_args,<br>    ...<br>)<br><br><span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> optuna</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">optuna_hp_space</span>(<span class="hljs-params">trial</span>):</span><br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&quot;learning_rate&quot;</span>: trial.suggest_float(<span class="hljs-string">&quot;learning_rate&quot;</span>, <span class="hljs-number">5e-6</span>, <span class="hljs-number">5e-4</span>, log=<span class="hljs-literal">True</span>),<br>        <span class="hljs-string">&quot;num_train_epochs&quot;</span>: trial.suggest_int(<span class="hljs-string">&quot;num_train_epochs&quot;</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>),<br>        <span class="hljs-string">&quot;seed&quot;</span>: trial.suggest_int(<span class="hljs-string">&quot;seed&quot;</span>, <span class="hljs-number">1</span>, <span class="hljs-number">42</span>),<br>    &#125;<br><br><span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> ray tune</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">ray_hp_space</span>():</span><br>    <span class="hljs-keyword">from</span> ray <span class="hljs-keyword">import</span> tune<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&quot;learning_rate&quot;</span>: tune.loguniform(<span class="hljs-number">5e-6</span>, <span class="hljs-number">5e-4</span>),<br>        <span class="hljs-string">&quot;num_train_epochs&quot;</span>: tune.choice(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>)),<br>        <span class="hljs-string">&quot;seed&quot;</span>: tune.choice(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">42</span>)),<br>    &#125;<br><br>trainer.hyperparameter_search(<br>    direction=<span class="hljs-string">&quot;maximize&quot;</span>, <span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> or direction=&quot;minimize&quot;</span><br>    hp_space=ray_hp_space, <span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> if you wanna use optuna, change it to optuna_hp_space</span><br>    backend=<span class="hljs-string">&quot;ray&quot;</span>, <span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> if you wanna use optuna, remove this argument</span><br>)<br></code></pre></td></tr></table></figure>  </details><p>  <img src="/images/%EC%9A%A9%EB%9F%89%EA%BD%89%EC%B0%B8.png" alt="ë‹¨ì  - ìš©ëŸ‰ê½‰ì°¸"></p></li></ul><p>ë˜í•œ <code>W&amp;B</code>ë¥¼ íŒ€ìœ¼ë¡œ ë§Œë“¤ì–´ì„œ íŒ€ì›ë“¤ì´ ì‹¤í—˜í•˜ëŠ” ê²°ê³¼ë“¤ì„ ì „ë¶€ ê³µìœ í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ë•ë¶„ì— ì‹¤íŒ¨í•œ ì‹¤í—˜ì´ë‚˜ ì„±ê³µí•œ ì‹¤í—˜ë“¤ì— ëŒ€í•´ì„œ chartë¥¼ í†µí•´ ë”ìš± ì‰½ê³  ì§ê´€ì ìœ¼ë¡œ ëª¨ë¸ì„ ê²€ì¦í•  ìˆ˜ ìˆì—ˆê³ , íŒ€ì›ê°„ ë” ë¹ ë¥¸ ê²°ê³¼ ê³µìœ ê°€ ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤. </p><p align="center">    <img src="/images/w0.png" height="300px"></p><p align="center">    <img src="/images/w1.png" style="display: inline" height="120px">    <img src="/images/w2.png" style="display: inline" height="120px"></p><p align="center">    <img src="/images/w3.png" style="display: inline" height="120px">    <img src="/images/w4.png" style="display: inline" height="120px"></p><h2 id="ğŸ’Œ-Thanks-to"><a href="#ğŸ’Œ-Thanks-to" class="headerlink" title="ğŸ’Œ Thanks to"></a>ğŸ’Œ Thanks to</h2><p><em><strong>ì²­ê³„ì‚°ì…°ë¥´íŒŒì˜ ë¹„ë°€ë³‘ê¸°, ì´ìœ ê²½ ë©˜í† ë‹˜.</strong></em></p><p align="center">    <img src="/images/notion_mentoring.png" style="display: inline" height="360px">    <img src="/images/notion_qna.png" style="display: inline" height="360px"></p><p>ì •ë§ ë°”ì˜ì‹  ì™€ì¤‘ì—ë„ ë§ì€ ê²ƒì„ ì•Œë ¤ì£¼ì‹œë ¤ê³  ì—´ì‹¬íˆ ì°¾ì•„ë³´ì‹œê³ , ë”°ë¡œ ê³µë¶€ë„ í•´ê°€ì‹œë©´ì„œ ì €í¬ì—ê²Œ ë§ì€ ë„ì›€ì„ ì£¼ì…¨ìŠµë‹ˆë‹¤. ì €í¬ì˜ ë“±ë°˜ì¼ì§€ì— ê°€ì¥ í° ê¸°ì—¬ë¥¼ í•˜ì‹  ì´ìœ ê²½ ë©˜í† ë‹˜ê»˜ ë‹¤ì‹œí•œë²ˆ ê°ì‚¬ì˜ ë§ì”€ ì „í•´ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.</p><br><p><em><strong>ì²­ê³„ì‚°ì…°ë¥´íŒŒ íŒ€ëª…ì— í•­ìƒ ë¶ˆë§Œì„ ê°€ì§€ì‹œëŠ” ì„±ì˜ˆë‹® ë©˜í† ë‹˜</strong></em><br><img src="/images/1.png"></p><p>ìœ ê²½ë©˜í† ë‹˜ì˜ ì‚¬ìƒíŒ¬ë‹µê²Œ ì €í¬íŒ€ì—ë„ ë§ì€ ê´€ì‹¬ê°€ì ¸ì£¼ì‹œê³  ì§€ì¼œë´ì£¼ì…”ì„œ ì •ë§ ë“ ë“ í•©ë‹ˆë‹¤. í•­ìƒ ë§ì”€ëª»ë“œë¦¬ëŠ”ê²Œ ì£„ì†¡í• ì •ë„ë¡œ, ë§ì€ ë„ì›€ ì£¼ì‹œê³  ì•Œë ¤ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤.</p><h2 id="ë§ˆì§€ë§‰ìœ¼ë¡œ"><a href="#ë§ˆì§€ë§‰ìœ¼ë¡œ" class="headerlink" title="ë§ˆì§€ë§‰ìœ¼ë¡œ"></a>ë§ˆì§€ë§‰ìœ¼ë¡œ</h2><p>ì €í¬ê°€ ì²˜ìŒì— ê³„íší–ˆë˜ <code>ê¸°ë¡</code>ê³¼ <code>ê³µìœ </code>ë¼ëŠ” ê°€ì¹˜ì— ìˆì–´ì„œë§Œí¼ì€ ì „ë°˜ì ìœ¼ë¡œ íŒ€ì› ëª¨ë‘ê°€ ë§Œì¡±í•  ìˆ˜ ìˆì—ˆë˜ í”„ë¡œì íŠ¸ì˜€ìŠµë‹ˆë‹¤.</p><p>ì²˜ìŒ í•©ì„ ë§ì¶¤ì—ë„ ë¶ˆêµ¬í•˜ê³  íŒ€ì› ëª¨ë‘ê°€ ë‹¤ìŒ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì–´ë– í•œ ì—­í• ì„ ìˆ˜í–‰í•˜ê³ , ì–´ë–¤ ì‹ìœ¼ë¡œ í˜‘ì—…ì„ í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì¼ì§€ ìŠ¤ìŠ¤ë¡œ ê¹¨ìš°ì¹  ìˆ˜ ìˆì—ˆë‹¤ëŠ” ì ì—ì„œ êµ‰ì¥íˆ ê³ ë¬´ì ì´ë©°, ë§ì€ ê¹¨ë‹¬ìŒì„ ì–»ì„ ìˆ˜ ìˆì—ˆë˜ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤.</p><p>ë„ˆë¬´ ì¢‹ì€ íŒ€ì›ë¶„ë“¤ê³¼ í•¨ê»˜í•  ìˆ˜ ìˆì–´ì„œ ì •ë§ ì¢‹ì•˜ê³  ë‹¤ìŒ ëŒ€íšŒê°€ ë„ˆë¬´ë‚˜ë„ ê¸°ë‹¤ë ¤ì§€ë„¤ìš”.</p><p>ì €í¬ì˜ ì´ì•¼ê¸°ê°€ ì¡°ê¸ˆì´ë¼ë„ ë„ì›€ì´ ë˜ì—ˆê¸¸ ë°”ë¼ë©´ì„œ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤.</p><p>ê¸´ ê¸€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.</p><h2 id="ğŸ¤œ-ë¶€ë¡-íŒ€ì›ë“¤-í•œë§ˆë””"><a href="#ğŸ¤œ-ë¶€ë¡-íŒ€ì›ë“¤-í•œë§ˆë””" class="headerlink" title="ğŸ¤œ ë¶€ë¡: íŒ€ì›ë“¤ í•œë§ˆë””"></a>ğŸ¤œ ë¶€ë¡: íŒ€ì›ë“¤ í•œë§ˆë””</h2><h3 id="ì¢‹ì•˜ë˜-ì "><a href="#ì¢‹ì•˜ë˜-ì " class="headerlink" title="ì¢‹ì•˜ë˜ ì "></a>ì¢‹ì•˜ë˜ ì </h3><ul><li>ìš”í•œ: ì² ì €í•˜ê²Œ ê¸°ë¡ì„ í•˜ê³ , ì‹¤í—˜ê²°ê³¼ë¥¼ ê³µìœ í–ˆë˜ ì ì´ ê°€ì¥ ì˜ í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŠ¹íˆ ë‹¤ì–‘í•œ í˜‘ì—…íˆ´ì„ ë‘ê³  ì‚¬ìš©í•œ ê²ƒë³´ë‹¤ ê·¸ ê¸°ëŠ¥ë“¤ì„ ë…¸ì…˜ì—ë‹¤ê°€ ì „ë¶€ í†µí•©í•˜ì—¬ ì‚¬ìš©í•œê²Œ í˜¼ë€ì´ ì ì–´ ì˜ ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</li><li>í•˜ê²¸: ì‹¤í—˜ ìì²´ë¥¼ ë‹¤ì–‘í•˜ê²Œ ì‹œë„í•˜ê³ , ì‹¤í—˜ ê³µìœ ê°€ ì˜ ë¬ë˜ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì´ì „ ì‹¤í—˜ì˜ ê²°ë¡ ì—ì„œ ë‹¤ìŒ ì‹¤í—˜ì€ ì–´ë–»ê²Œ í• ì§€ë¥¼ ì •í•œ ê²ƒë„ ì¢‹ì•˜ìŠµë‹ˆë‹¤.</li><li>ì¤€ì˜: íŒ€ì› ê°„ì— ê³µìœ ê°€ ì˜ë˜ì„œ ì¢‹ì•˜ìŠµë‹ˆë‹¤. ê¸°ë¡ì´ ì˜ë˜ë‹¤ë³´ë‹ˆ ì œê°€ í•˜ì§€ ì•Šì€ ì‹¤í—˜ì—ì„œë„ ì•„ì´ë””ì–´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</li><li>ì§„ì›: íŒ€ì›ë“¤ë¼ë¦¬ ê²°ê³¼ ê³µìœ ì™€ ê¸°ë¡ì´ ì˜ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ì—´ì‹¬íˆ í•œ ë§Œí¼ ìµœì¢…ì ìœ¼ë¡œë„ ê´œì°®ì€ ê²°ê³¼ë¥¼ ì–»ì–´ì„œ ë§Œì¡±í•©ë‹ˆë‹¤.</li><li>ë¯¼ìˆ˜: ì‹¤í—˜ì„ ë§ì´ í–ˆë˜ ê²ƒ. ì œì¶œ íšŸìˆ˜ë¥¼ ê½‰ ì±„ì›Œì„œ ì“´ê²Œ ì¢‹ì•˜ìŠµë‹ˆë‹¤.</li><li>í¬ì˜: ì˜ê²¬ ê³µìœ ê°€ ì˜ ë˜ì–´ì„œ ë‚´ê°€ í•˜ì§€ ì•Šì€ ì‹¤í—˜ì—ì„œë„ ì§€ì‹ì„ ì–»ì„ ìˆ˜ ìˆì–´ì„œ ì¢‹ì•˜ìŠµë‹ˆë‹¤. íŒ€ì›ë“¤ê³¼ ë©˜í† ë‹˜ì´ ì§€ì‹ì´ ë§ì•„ì„œ ì§„ì§œ ë¹ ë¥´ê²Œ ë°°ì› ìŠµë‹ˆë‹¤.</li><li>ì§„ì„± : ê°ì ì‹¤í—˜ì— ìˆì–´ í†µì œë³€ì¸ ì„¤ì •ì„ ì² ì €íˆ í•˜ê³  ê¸°ë¡ì„ ì„¸ì„¸í•˜ê²Œ í•´, ì‹¤í—˜ì˜ íš¨ê³¼ë¥¼ ê³µìœ í•˜ê¸° ì¢‹ì•˜ìŠµë‹ˆë‹¤.</li></ul><h3 id="ì•„ì‰¬ìš´-ì "><a href="#ì•„ì‰¬ìš´-ì " class="headerlink" title="ì•„ì‰¬ìš´ ì "></a>ì•„ì‰¬ìš´ ì </h3><ul><li>ìš”í•œ: ì—¬ëŸ¬ ì‹¤í—˜ ì•„ì´ë””ì–´ë“¤ì´ ìˆì—ˆì§€ë§Œ, ë§‰íŒìœ¼ë¡œ ê°ˆ ìˆ˜ë¡ ì„±ëŠ¥ì— ì§‘ì°©í•˜ì—¬ í° ëª¨ë¸ë¡œë§Œ ì‹¤í—˜ì„ í•˜ëŠë¼ ëª¨ë“  ì•„ì´ë””ì–´ë“¤ì— ëŒ€í•´ì„œ ì‹¤í—˜ì„ í•˜ì§€ ëª»í–ˆë˜ ê²ƒì´ ì•„ì‰½ìŠµë‹ˆë‹¤.</li><li>í•˜ê²¸ : ê°„ê·¹ì´ ì ì€ validation setì„ ê²°êµ­ì€ ëª»ì°¾ì•˜ë‹¤. â†’ ì–´ë–»ê²Œ ì°¾ì„ ìˆ˜ ìˆì„ì§€ëŠ” ì•„ì§ë„ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤. ì„±ëŠ¥ë©´ì—ì„œë„ í° ë„ì›€ì´ ë˜ì§€ ì•Šì•„ì„œ ì•„ì‰¬ì› ìŠµë‹ˆë‹¤.</li><li>ì¤€ì˜: ëª¨ë¸ ì‘ì—…ì„ í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° ê´€ë ¨í•´ì„œ ë§ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•„ë³´ê³  ì‹¶ì—ˆì§€ë§Œ ê²°ê³¼ë¥¼ ì œëŒ€ë¡œ ë‚´ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.</li><li>ì§„ì›: ëª¨ë¸ì„ ìˆ˜ì •í•˜ëŠ” ì‘ì—…ì„ ë§ì´ í•˜ì§€ ëª»í•´ ì•„ì‰¬ì› ìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ì§€ë§Œ, ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì˜¬ë¦¬ëŠ”ë° í¬ê²Œ ê¸°ì—¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.</li><li>ë¯¼ìˆ˜: ëª¨ë¸ì„ íƒœìŠ¤í¬ì— ë§ê²Œ ë³´ë‹¤ ì ê·¹ì ìœ¼ë¡œ ë³€í˜•í•˜ë ¤ëŠ” ì‹œë„ë¥¼ í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.</li><li>í¬ì˜: ëŒ€íšŒ ì´ˆê¸° ìƒí™œ ìŠ¤ì¼€ì¤„ì´ ê¼¬ì—¬ì„œ ì‹œê°„ ë‚­ë¹„ë¥¼ ë§ì´ í–ˆìŠµë‹ˆë‹¤. ìƒí™œ ìŠµê´€ì„ ì˜ ì¡ê³  ì‹œì‘í•˜ëŠ” ê²Œ ì¤‘ìš”í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.</li><li>ì§„ì„± : ìˆ˜ë™ì ìœ¼ë¡œ í•  ì¼ì„ ë°›ì•„ì„œ í•˜ê±°ë‚˜, ë‹¤ë¥¸ ì‚¬ëŒì˜ branchì— ë§ë¶™ì—¬ì„œ ì‘ì€ ì‹¤í—˜ë“¤ë§Œ í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ëŒ€íšŒì—ì„œëŠ” ë‚˜ë„ ì ê·¹ì ìœ¼ë¡œ ë…¼ë¬¸ ë“±ì—ì„œ ì•„ì´ë””ì–´ë¥¼ ì–»ì–´ì™€ í¼ì§í•˜ê²Œ(ë¹ ë¥´ê²Œ) ì •í™•í•˜ê²Œ êµ¬í˜„í•˜ëŠ” ì—°ìŠµì„ í•´ë³´ì.</li></ul><h3 id="ê°œì„ í• -ì "><a href="#ê°œì„ í• -ì " class="headerlink" title="ê°œì„ í•  ì "></a>ê°œì„ í•  ì </h3><ul><li>ìš”í•œ: ì„±ëŠ¥ì€ ì–´ì°¨í”¼ ì˜¤ë¥¼ ê²ƒì´ê¸° ë•Œë¬¸ì—, ë¹„ìŠ·í•œ ì‹¤í—˜ì„ ì—¬ëŸ¬ë²ˆ í•˜ëŠ” ê²ƒë³´ë‹¤ëŠ” ë– ì˜¬ë¦° ì•„ì´ë””ì–´ë“¤ì— ëŒ€í•´ ì „ë¶€ ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ í•´ë´ì•¼ê² ìŠµë‹ˆë‹¤.</li><li>í•˜ê²¸: ì¼ë‹¨ ê°•ì˜ë¶€í„° ë“¤ì–´ì„œ ë§¨ë•…ì— í—¤ë”©í•˜ì§€ ì•Šê¸°</li><li>ì¤€ì˜: ê°•ì˜ ë¹ ë¥´ê²Œ ë“£ê¸°. ë°ì´í„° ë¹ ë¥´ê²Œ í›‘ì–´ë³´ê¸°. ëª¨ë¸ ëœ¯ì–´ë³´ê¸°.</li><li>ì§„ì›: ëª¨ë¸ì„ ìˆ˜ì •í•´ë³´ëŠ” ì‹¤í—˜ì„ ì§„í–‰í•˜ê³ , í™•ì‹¤í•˜ê²Œ ì„±ëŠ¥ í–¥ìƒì„ ì´ë£¨ê¸° ìœ„í•´ ì‹¤í—˜ì„ ì§„í–‰í•  ë•Œ ì¡°ê¸ˆ ë” ëª…í™•í•œ ê·¼ê±°ë‚˜ ë°©ë²•ì„ ë¯¸ë¦¬ ì¡°ì‚¬í•´ë³´ê³  ì§„í–‰í•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ (e.g. ë…¼ë¬¸ ì½ì–´ì„œ train íšŸìˆ˜ ì •í•˜ê¸°).</li><li>ë¯¼ìˆ˜: ì–´ë–¤ì‹ì˜ ë³€í˜•ì´ í•´ë‹¹ íƒœìŠ¤í¬ì— ì í•©í•œì§€ ë‹¨ìˆœ ì ìˆ˜ì™€ ëŠë‚Œ ì´ì™¸ì— ì •ëŸ‰ì ìœ¼ë¡œ ê²€ì¦í•  ìˆ˜ ìˆëŠ” ë°©ë²•ë¡ ì„ ìƒê°í•´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</li><li>í¬ì˜: ì²«ë‚  ì§„ì§œ ë¹ ë¥´ê²Œ ê°•ì˜ ë‹¤ ë“£ê¸°. 10ì‹œ~12ì‹œ ì‚¬ì´ ì‹œê°„ ì˜ ì´ìš©í•˜ê¸°. ì´ë™ í›„ ë°”ë¡œ ì‹œì‘í•˜ê¸°, 12ì‹œ ë„˜ìœ¼ë©´ ì§‘ì—ì„œ ê³µë¶€í•  ìƒê°í•˜ì§€ ë§ê¸°. EDAë¥¼ ë„ˆë¬´ ì˜¤ë˜ í•˜ê³  raw ë°ì´í„°ë¥¼ ë„ˆë¬´ ë§ì´ ë³´ë©´ ì‹œê°„ ë‚­ë¹„ì¼ìˆ˜ë„.</li><li>ì§„ì„± : í›„ë°˜ë¶€ì— ê¸°ë¡ì„ í•˜ëŠ” ë°ì— ì‹ ê²½ì„ ë§ì´ ëª»ì¼ìŠµë‹ˆë‹¤. ê²°êµ­ ë‚¨ëŠ”ê±´ ê¸°ë¡ì´ë‹ˆ ë‹¤ìŒ ëŒ€íšŒ ê¸´ ê¸°ê°„ë™ì•ˆì—ë„ ê¾¸ì¤€íˆ ê¸°ë¡í•˜ì.</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
